{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is intended to explore the 1.1.3.15 data and figure out the storyline.<br/><br/>Copyright (C) 2019  Martin Engqvist Lab<br/>This program is free software: you can redistribute it and/or modify<br/>it under the terms of the GNU General Public License as published by<br/>the Free Software Foundation, either version 3 of the License, or<br/>(at your option) any later version.<br/>This program is distributed in the hope that it will be useful,<br/>but WITHOUT ANY WARRANTY; without even the implied warranty of<br/>MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the<br/>GNU General Public License for more details.<br/>You should have received a copy of the GNU General Public License<br/>along with this program.  If not, see <http://www.gnu.org/licenses/>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard variables loaded, you are good to go!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from os.path import join, dirname, basename, exists, isdir\n",
    "\n",
    "### Load environmental variables from the project root directory ###\n",
    "# find .env automagically by walking up directories until it's found\n",
    "dotenv_path = find_dotenv()\n",
    "\n",
    "# load up the entries as environment variables\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "# now you can get the variables using their names\n",
    "\n",
    "# Check whether a network drive has been specified\n",
    "DATABASE = os.environ.get(\"NETWORK_URL\")\n",
    "if DATABASE == 'None':\n",
    "    pass\n",
    "else:\n",
    "    pass\n",
    "    #mount network drive here\n",
    "\n",
    "# set up directory paths\n",
    "CURRENT_DIR = os.getcwd()\n",
    "PROJ = dirname(dotenv_path) # project root directory\n",
    "\n",
    "DATA = join(PROJ, 'data') #data directory\n",
    "RAW_EXTERNAL = join(DATA, 'raw_external') # external data raw directory\n",
    "RAW_INTERNAL = join(DATA, 'raw_internal') # internal data raw directory\n",
    "INTERMEDIATE = join(DATA, 'intermediate') # intermediate data directory\n",
    "FINAL = join(DATA, 'final') # final data directory\n",
    "\n",
    "RESULTS = join(PROJ, 'results') # output directory\n",
    "FIGURES = join(RESULTS, 'figures') # figure output directory\n",
    "PICTURES = join(RESULTS, 'pictures') # picture output directory\n",
    "\n",
    "print('Standard variables loaded, you are good to go!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle, Patch\n",
    "# import seaborn as sns; sns.set(style=\"ticks\", color_codes=True)\n",
    "\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "import networkx as nx\n",
    "from brenparse import parser\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import string\n",
    "import matplotlib.gridspec as gridspec\n",
    "from cycler import cycler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the 1.1.3.15 sequences encoded using UniRep embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>av_1</th>\n",
       "      <th>av_2</th>\n",
       "      <th>av_3</th>\n",
       "      <th>av_4</th>\n",
       "      <th>av_5</th>\n",
       "      <th>av_6</th>\n",
       "      <th>av_7</th>\n",
       "      <th>av_8</th>\n",
       "      <th>av_9</th>\n",
       "      <th>...</th>\n",
       "      <th>fc_1891</th>\n",
       "      <th>fc_1892</th>\n",
       "      <th>fc_1893</th>\n",
       "      <th>fc_1894</th>\n",
       "      <th>fc_1895</th>\n",
       "      <th>fc_1896</th>\n",
       "      <th>fc_1897</th>\n",
       "      <th>fc_1898</th>\n",
       "      <th>fc_1899</th>\n",
       "      <th>fc_1900</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Q9LRS0</td>\n",
       "      <td>0.015368</td>\n",
       "      <td>0.207102</td>\n",
       "      <td>0.076687</td>\n",
       "      <td>-0.040839</td>\n",
       "      <td>-0.116888</td>\n",
       "      <td>0.069290</td>\n",
       "      <td>0.011434</td>\n",
       "      <td>-0.046359</td>\n",
       "      <td>-0.004900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314290</td>\n",
       "      <td>0.790594</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>0.092050</td>\n",
       "      <td>-2.026679</td>\n",
       "      <td>-0.509705</td>\n",
       "      <td>0.087245</td>\n",
       "      <td>-1.506297</td>\n",
       "      <td>0.134522</td>\n",
       "      <td>0.133363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Q9NYQ3</td>\n",
       "      <td>0.008693</td>\n",
       "      <td>0.174844</td>\n",
       "      <td>0.069413</td>\n",
       "      <td>-0.042212</td>\n",
       "      <td>-0.134430</td>\n",
       "      <td>0.074950</td>\n",
       "      <td>0.001461</td>\n",
       "      <td>-0.043215</td>\n",
       "      <td>-0.005424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089248</td>\n",
       "      <td>-0.263056</td>\n",
       "      <td>-0.042254</td>\n",
       "      <td>1.496964</td>\n",
       "      <td>-5.197632</td>\n",
       "      <td>-0.705789</td>\n",
       "      <td>0.733266</td>\n",
       "      <td>-2.503108</td>\n",
       "      <td>0.237560</td>\n",
       "      <td>0.250488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>P37339</td>\n",
       "      <td>0.024516</td>\n",
       "      <td>0.012727</td>\n",
       "      <td>0.070110</td>\n",
       "      <td>-0.008737</td>\n",
       "      <td>-0.356430</td>\n",
       "      <td>0.079727</td>\n",
       "      <td>-0.072076</td>\n",
       "      <td>0.021245</td>\n",
       "      <td>-0.004387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>-0.355467</td>\n",
       "      <td>0.982859</td>\n",
       "      <td>-12.764019</td>\n",
       "      <td>0.079447</td>\n",
       "      <td>0.277420</td>\n",
       "      <td>-0.994416</td>\n",
       "      <td>0.123665</td>\n",
       "      <td>4.128018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Q24JJ8</td>\n",
       "      <td>0.011160</td>\n",
       "      <td>0.157242</td>\n",
       "      <td>0.094497</td>\n",
       "      <td>-0.049337</td>\n",
       "      <td>-0.101914</td>\n",
       "      <td>0.079308</td>\n",
       "      <td>0.020020</td>\n",
       "      <td>-0.047959</td>\n",
       "      <td>-0.003755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467036</td>\n",
       "      <td>0.284700</td>\n",
       "      <td>-0.034987</td>\n",
       "      <td>0.619065</td>\n",
       "      <td>0.641811</td>\n",
       "      <td>-1.148384</td>\n",
       "      <td>-0.318679</td>\n",
       "      <td>-2.219294</td>\n",
       "      <td>0.175719</td>\n",
       "      <td>0.342886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>B8AUI3</td>\n",
       "      <td>0.015618</td>\n",
       "      <td>0.195817</td>\n",
       "      <td>0.077877</td>\n",
       "      <td>-0.038937</td>\n",
       "      <td>-0.114840</td>\n",
       "      <td>0.062852</td>\n",
       "      <td>0.023076</td>\n",
       "      <td>-0.044319</td>\n",
       "      <td>-0.004918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174403</td>\n",
       "      <td>-0.260183</td>\n",
       "      <td>-0.017469</td>\n",
       "      <td>0.329009</td>\n",
       "      <td>-3.487079</td>\n",
       "      <td>-0.563793</td>\n",
       "      <td>-1.393169</td>\n",
       "      <td>-1.276244</td>\n",
       "      <td>0.272283</td>\n",
       "      <td>-0.236024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5701 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid      av_1      av_2      av_3      av_4      av_5      av_6  \\\n",
       "33  Q9LRS0  0.015368  0.207102  0.076687 -0.040839 -0.116888  0.069290   \n",
       "34  Q9NYQ3  0.008693  0.174844  0.069413 -0.042212 -0.134430  0.074950   \n",
       "35  P37339  0.024516  0.012727  0.070110 -0.008737 -0.356430  0.079727   \n",
       "36  Q24JJ8  0.011160  0.157242  0.094497 -0.049337 -0.101914  0.079308   \n",
       "37  B8AUI3  0.015618  0.195817  0.077877 -0.038937 -0.114840  0.062852   \n",
       "\n",
       "        av_7      av_8      av_9  ...   fc_1891   fc_1892   fc_1893   fc_1894  \\\n",
       "33  0.011434 -0.046359 -0.004900  ...  0.314290  0.790594 -0.073425  0.092050   \n",
       "34  0.001461 -0.043215 -0.005424  ...  0.089248 -0.263056 -0.042254  1.496964   \n",
       "35 -0.072076  0.021245 -0.004387  ...  0.002008 -0.151272 -0.355467  0.982859   \n",
       "36  0.020020 -0.047959 -0.003755  ...  0.467036  0.284700 -0.034987  0.619065   \n",
       "37  0.023076 -0.044319 -0.004918  ...  0.174403 -0.260183 -0.017469  0.329009   \n",
       "\n",
       "      fc_1895   fc_1896   fc_1897   fc_1898   fc_1899   fc_1900  \n",
       "33  -2.026679 -0.509705  0.087245 -1.506297  0.134522  0.133363  \n",
       "34  -5.197632 -0.705789  0.733266 -2.503108  0.237560  0.250488  \n",
       "35 -12.764019  0.079447  0.277420 -0.994416  0.123665  4.128018  \n",
       "36   0.641811 -1.148384 -0.318679 -2.219294  0.175719  0.342886  \n",
       "37  -3.487079 -0.563793 -1.393169 -1.276244  0.272283 -0.236024  \n",
       "\n",
       "[5 rows x 5701 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>av_1</th>\n",
       "      <th>av_2</th>\n",
       "      <th>av_3</th>\n",
       "      <th>av_4</th>\n",
       "      <th>av_5</th>\n",
       "      <th>av_6</th>\n",
       "      <th>av_7</th>\n",
       "      <th>av_8</th>\n",
       "      <th>av_9</th>\n",
       "      <th>...</th>\n",
       "      <th>fc_1891</th>\n",
       "      <th>fc_1892</th>\n",
       "      <th>fc_1893</th>\n",
       "      <th>fc_1894</th>\n",
       "      <th>fc_1895</th>\n",
       "      <th>fc_1896</th>\n",
       "      <th>fc_1897</th>\n",
       "      <th>fc_1898</th>\n",
       "      <th>fc_1899</th>\n",
       "      <th>fc_1900</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>D5MNA0</td>\n",
       "      <td>0.005720</td>\n",
       "      <td>0.144893</td>\n",
       "      <td>0.087827</td>\n",
       "      <td>-0.028350</td>\n",
       "      <td>-0.115191</td>\n",
       "      <td>0.140921</td>\n",
       "      <td>0.024286</td>\n",
       "      <td>-0.015941</td>\n",
       "      <td>-0.004543</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.699620</td>\n",
       "      <td>-0.425998</td>\n",
       "      <td>-0.048586</td>\n",
       "      <td>0.894642</td>\n",
       "      <td>-5.685828</td>\n",
       "      <td>1.162903</td>\n",
       "      <td>0.466842</td>\n",
       "      <td>1.646118</td>\n",
       "      <td>-2.875165</td>\n",
       "      <td>-1.577959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>A9QH69</td>\n",
       "      <td>0.010057</td>\n",
       "      <td>0.200460</td>\n",
       "      <td>0.092278</td>\n",
       "      <td>-0.044776</td>\n",
       "      <td>-0.151360</td>\n",
       "      <td>0.093140</td>\n",
       "      <td>-0.047560</td>\n",
       "      <td>-0.036216</td>\n",
       "      <td>-0.004398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175783</td>\n",
       "      <td>-0.203717</td>\n",
       "      <td>-0.694060</td>\n",
       "      <td>1.253930</td>\n",
       "      <td>-1.231092</td>\n",
       "      <td>-1.365787</td>\n",
       "      <td>0.013075</td>\n",
       "      <td>-2.970456</td>\n",
       "      <td>-0.251001</td>\n",
       "      <td>-0.182736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>A9QH71</td>\n",
       "      <td>0.009455</td>\n",
       "      <td>0.219847</td>\n",
       "      <td>0.103803</td>\n",
       "      <td>-0.050824</td>\n",
       "      <td>-0.151323</td>\n",
       "      <td>0.089220</td>\n",
       "      <td>-0.036848</td>\n",
       "      <td>-0.034098</td>\n",
       "      <td>-0.005225</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.157484</td>\n",
       "      <td>0.843793</td>\n",
       "      <td>-1.082651</td>\n",
       "      <td>0.641018</td>\n",
       "      <td>0.119636</td>\n",
       "      <td>-1.160653</td>\n",
       "      <td>0.113823</td>\n",
       "      <td>-2.279760</td>\n",
       "      <td>-1.942496</td>\n",
       "      <td>-0.435206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>Q9CG58</td>\n",
       "      <td>0.013375</td>\n",
       "      <td>0.151428</td>\n",
       "      <td>0.068151</td>\n",
       "      <td>-0.040234</td>\n",
       "      <td>-0.185927</td>\n",
       "      <td>0.091063</td>\n",
       "      <td>-0.046391</td>\n",
       "      <td>-0.040538</td>\n",
       "      <td>-0.005390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.472637</td>\n",
       "      <td>0.943567</td>\n",
       "      <td>-0.594633</td>\n",
       "      <td>0.482976</td>\n",
       "      <td>-4.980826</td>\n",
       "      <td>-1.161524</td>\n",
       "      <td>0.885641</td>\n",
       "      <td>-1.171051</td>\n",
       "      <td>-0.503931</td>\n",
       "      <td>-0.224056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>Q5SM78</td>\n",
       "      <td>0.006447</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.019374</td>\n",
       "      <td>-0.024663</td>\n",
       "      <td>0.129485</td>\n",
       "      <td>0.051069</td>\n",
       "      <td>-0.339259</td>\n",
       "      <td>-0.028680</td>\n",
       "      <td>-0.008576</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.817560</td>\n",
       "      <td>-0.619732</td>\n",
       "      <td>-3.377045</td>\n",
       "      <td>1.294015</td>\n",
       "      <td>-3.438791</td>\n",
       "      <td>-0.503038</td>\n",
       "      <td>1.146056</td>\n",
       "      <td>2.180835</td>\n",
       "      <td>3.405268</td>\n",
       "      <td>-0.993080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5701 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         uid      av_1      av_2      av_3      av_4      av_5      av_6  \\\n",
       "1439  D5MNA0  0.005720  0.144893  0.087827 -0.028350 -0.115191  0.140921   \n",
       "1440  A9QH69  0.010057  0.200460  0.092278 -0.044776 -0.151360  0.093140   \n",
       "1441  A9QH71  0.009455  0.219847  0.103803 -0.050824 -0.151323  0.089220   \n",
       "1442  Q9CG58  0.013375  0.151428  0.068151 -0.040234 -0.185927  0.091063   \n",
       "1443  Q5SM78  0.006447  0.011494  0.019374 -0.024663  0.129485  0.051069   \n",
       "\n",
       "          av_7      av_8      av_9  ...   fc_1891   fc_1892   fc_1893  \\\n",
       "1439  0.024286 -0.015941 -0.004543  ... -0.699620 -0.425998 -0.048586   \n",
       "1440 -0.047560 -0.036216 -0.004398  ...  0.175783 -0.203717 -0.694060   \n",
       "1441 -0.036848 -0.034098 -0.005225  ... -0.157484  0.843793 -1.082651   \n",
       "1442 -0.046391 -0.040538 -0.005390  ...  0.472637  0.943567 -0.594633   \n",
       "1443 -0.339259 -0.028680 -0.008576  ... -0.817560 -0.619732 -3.377045   \n",
       "\n",
       "       fc_1894   fc_1895   fc_1896   fc_1897   fc_1898   fc_1899   fc_1900  \n",
       "1439  0.894642 -5.685828  1.162903  0.466842  1.646118 -2.875165 -1.577959  \n",
       "1440  1.253930 -1.231092 -1.365787  0.013075 -2.970456 -0.251001 -0.182736  \n",
       "1441  0.641018  0.119636 -1.160653  0.113823 -2.279760 -1.942496 -0.435206  \n",
       "1442  0.482976 -4.980826 -1.161524  0.885641 -1.171051 -0.503931 -0.224056  \n",
       "1443  1.294015 -3.438791 -0.503038  1.146056  2.180835  3.405268 -0.993080  \n",
       "\n",
       "[5 rows x 5701 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1411, 5701)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_unirep(uni_filepath, prop_filepath, ec='1.1.3.15', sep=','):\n",
    "    '''\n",
    "    Load unirep embeddings into a data frame\n",
    "    '''\n",
    "    # load data and drop duplicates\n",
    "    unirep = pd.read_csv(uni_filepath, sep=sep)\n",
    "\n",
    "    # replace the first column with identifiers\n",
    "    unirep['Unnamed: 0'] = [i.split(';')[0] for i in unirep['Unnamed: 0']]\n",
    "\n",
    "    # re-name column\n",
    "    unirep = unirep.rename(columns={'Unnamed: 0':'uid'}).drop_duplicates()\n",
    "\n",
    "    # load uid to ec mapping and merge with property data\n",
    "    uid_ec = pd.read_csv(prop_filepath, sep='\\t').drop_duplicates()\n",
    "\n",
    "    # merge with ec data\n",
    "    unirep_merged = unirep.merge(uid_ec, on='uid')\n",
    "\n",
    "    # keep only a certain ec\n",
    "    if ec == 'all':\n",
    "        df_unirep = unirep_merged.drop('ec', axis=1)\n",
    "    else:\n",
    "        df_unirep = unirep_merged[unirep_merged.ec==ec].drop('ec', axis=1)\n",
    "\n",
    "    return df_unirep\n",
    "\n",
    "\n",
    "df_unirep = load_unirep(uni_filepath=join(INTERMEDIATE, 'brenda_2017_1', '1_1_3__BRENDA_sequences_filtered_2017_1_unirep.csv'),\n",
    "                       prop_filepath=join(FINAL, 'brenda_2017_1', 'ec_uid_org_from_fasta_2017_1.tsv'),\n",
    "                       ec='1.1.3.15')\n",
    "\n",
    "display(df_unirep.head())\n",
    "display(df_unirep.tail())\n",
    "display(df_unirep.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the enzyme property data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>taxid</th>\n",
       "      <th>organism</th>\n",
       "      <th>superkingdom</th>\n",
       "      <th>ph</th>\n",
       "      <th>temperature</th>\n",
       "      <th>pfam</th>\n",
       "      <th>ec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q9LRS0</td>\n",
       "      <td>3702.0</td>\n",
       "      <td>Arabidopsis thaliana</td>\n",
       "      <td>Eukaryota</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1.3.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q9NYQ3</td>\n",
       "      <td>9606.0</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>Eukaryota</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1.3.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P37339</td>\n",
       "      <td>83333.0</td>\n",
       "      <td>Escherichia coli</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>7.01</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1.3.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q24JJ8</td>\n",
       "      <td>3702.0</td>\n",
       "      <td>Arabidopsis thaliana</td>\n",
       "      <td>Eukaryota</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1.3.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B8AUI3</td>\n",
       "      <td>39946.0</td>\n",
       "      <td>Oryza sativa</td>\n",
       "      <td>Eukaryota</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1.3.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      uid    taxid              organism superkingdom    ph  temperature pfam  \\\n",
       "0  Q9LRS0   3702.0  Arabidopsis thaliana    Eukaryota   NaN          NaN  NaN   \n",
       "1  Q9NYQ3   9606.0          Homo sapiens    Eukaryota   NaN          NaN  NaN   \n",
       "2  P37339  83333.0      Escherichia coli     Bacteria  7.01         36.0  NaN   \n",
       "3  Q24JJ8   3702.0  Arabidopsis thaliana    Eukaryota   NaN          NaN  NaN   \n",
       "4  B8AUI3  39946.0          Oryza sativa    Eukaryota   NaN          NaN  NaN   \n",
       "\n",
       "         ec  \n",
       "0  1.1.3.15  \n",
       "1  1.1.3.15  \n",
       "2  1.1.3.15  \n",
       "3  1.1.3.15  \n",
       "4  1.1.3.15  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>taxid</th>\n",
       "      <th>organism</th>\n",
       "      <th>superkingdom</th>\n",
       "      <th>ph</th>\n",
       "      <th>temperature</th>\n",
       "      <th>pfam</th>\n",
       "      <th>ec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>B9REU4</td>\n",
       "      <td>3988.0</td>\n",
       "      <td>Ricinus communis</td>\n",
       "      <td>Eukaryota</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PF07250, PF09118</td>\n",
       "      <td>1.1.3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2051</th>\n",
       "      <td>B9RYU4</td>\n",
       "      <td>3988.0</td>\n",
       "      <td>Ricinus communis</td>\n",
       "      <td>Eukaryota</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PF07250, PF09118</td>\n",
       "      <td>1.1.3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2052</th>\n",
       "      <td>B9R845</td>\n",
       "      <td>3988.0</td>\n",
       "      <td>Ricinus communis</td>\n",
       "      <td>Eukaryota</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PF07250, PF09118</td>\n",
       "      <td>1.1.3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2053</th>\n",
       "      <td>M5CRB8</td>\n",
       "      <td>1118156.0</td>\n",
       "      <td>Stenotrophomonas maltophilia</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>7.27</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1.3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054</th>\n",
       "      <td>B8MB95</td>\n",
       "      <td>441959.0</td>\n",
       "      <td>Talaromyces stipitatus</td>\n",
       "      <td>Eukaryota</td>\n",
       "      <td>5.60</td>\n",
       "      <td>25.0</td>\n",
       "      <td>PF09118</td>\n",
       "      <td>1.1.3.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         uid      taxid                      organism superkingdom    ph  \\\n",
       "2050  B9REU4     3988.0              Ricinus communis    Eukaryota   NaN   \n",
       "2051  B9RYU4     3988.0              Ricinus communis    Eukaryota   NaN   \n",
       "2052  B9R845     3988.0              Ricinus communis    Eukaryota   NaN   \n",
       "2053  M5CRB8  1118156.0  Stenotrophomonas maltophilia     Bacteria  7.27   \n",
       "2054  B8MB95   441959.0        Talaromyces stipitatus    Eukaryota  5.60   \n",
       "\n",
       "      temperature              pfam       ec  \n",
       "2050          NaN  PF07250, PF09118  1.1.3.9  \n",
       "2051          NaN  PF07250, PF09118  1.1.3.9  \n",
       "2052          NaN  PF07250, PF09118  1.1.3.9  \n",
       "2053         30.0               NaN  1.1.3.9  \n",
       "2054         25.0           PF09118  1.1.3.9  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load enzyme property information\n",
    "filepath = join(FINAL, 'brenda_2017_1', '1-1-3-n_identifier_info_2017_1.tsv')\n",
    "uid_property = pd.read_csv(filepath, sep='\\t').drop_duplicates()\n",
    "\n",
    "uid_property.drop(['lineage_identifiers', 'lineage_ranks', 'lineage_names'], \n",
    "                  inplace=True,\n",
    "                 axis=1)\n",
    "\n",
    "# load uid to ec mapping and merge with property data\n",
    "filepath = join(FINAL, 'brenda_2017_1', 'ec_uid_org_from_fasta_2017_1.tsv')\n",
    "uid_ec = pd.read_csv(filepath, sep='\\t').drop_duplicates()\n",
    "\n",
    "# merge with the ec mapping\n",
    "uid_data = uid_property.merge(uid_ec, on=['uid'])\n",
    "\n",
    "# sort in the same order as the unirep data\n",
    "uid_data['sort_cat'] = pd.Categorical(uid_data['uid'], \n",
    "                                          categories=df_unirep.uid, \n",
    "                                          ordered=True)\n",
    "uid_data.sort_values('sort_cat', inplace=True)\n",
    "uid_data.reset_index(inplace=True)\n",
    "\n",
    "# drop columns that aren't needed\n",
    "uid_data = uid_data.drop(['sort_cat', 'index'], axis=1)\n",
    "\n",
    "display(uid_data.head())\n",
    "display(uid_data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load experimental data and combine with enzyme property data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>synthesized</th>\n",
       "      <th>substrate_available</th>\n",
       "      <th>total_soluble</th>\n",
       "      <th>total_active</th>\n",
       "      <th>batch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A009NBJ7</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A011R8E6</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A017H745</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A024H7W1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A073CBY9</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>first</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          uid synthesized substrate_available total_soluble total_active  \\\n",
       "0  A0A009NBJ7         Yes                 Yes            No          NaN   \n",
       "1  A0A011R8E6         Yes                 Yes            No          NaN   \n",
       "2  A0A017H745         Yes                 Yes            No          NaN   \n",
       "3  A0A024H7W1         Yes                 Yes           Yes          Yes   \n",
       "4  A0A073CBY9         Yes                 Yes           Yes           No   \n",
       "\n",
       "   batch  \n",
       "0  first  \n",
       "1  first  \n",
       "2  first  \n",
       "3  first  \n",
       "4  first  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>taxid</th>\n",
       "      <th>organism</th>\n",
       "      <th>superkingdom</th>\n",
       "      <th>ph</th>\n",
       "      <th>temperature</th>\n",
       "      <th>pfam</th>\n",
       "      <th>ec</th>\n",
       "      <th>synthesized</th>\n",
       "      <th>substrate_available</th>\n",
       "      <th>total_soluble</th>\n",
       "      <th>total_active</th>\n",
       "      <th>batch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q9LRS0</td>\n",
       "      <td>3702.0</td>\n",
       "      <td>Arabidopsis thaliana</td>\n",
       "      <td>Eukaryota</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1.3.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q9NYQ3</td>\n",
       "      <td>9606.0</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>Eukaryota</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1.3.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P37339</td>\n",
       "      <td>83333.0</td>\n",
       "      <td>Escherichia coli</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>7.01</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1.3.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q24JJ8</td>\n",
       "      <td>3702.0</td>\n",
       "      <td>Arabidopsis thaliana</td>\n",
       "      <td>Eukaryota</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1.3.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B8AUI3</td>\n",
       "      <td>39946.0</td>\n",
       "      <td>Oryza sativa</td>\n",
       "      <td>Eukaryota</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1.3.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      uid    taxid              organism superkingdom    ph  temperature pfam  \\\n",
       "0  Q9LRS0   3702.0  Arabidopsis thaliana    Eukaryota   NaN          NaN  NaN   \n",
       "1  Q9NYQ3   9606.0          Homo sapiens    Eukaryota   NaN          NaN  NaN   \n",
       "2  P37339  83333.0      Escherichia coli     Bacteria  7.01         36.0  NaN   \n",
       "3  Q24JJ8   3702.0  Arabidopsis thaliana    Eukaryota   NaN          NaN  NaN   \n",
       "4  B8AUI3  39946.0          Oryza sativa    Eukaryota   NaN          NaN  NaN   \n",
       "\n",
       "         ec synthesized substrate_available total_soluble total_active batch  \n",
       "0  1.1.3.15         NaN                 NaN           NaN          NaN   NaN  \n",
       "1  1.1.3.15         NaN                 NaN           NaN          NaN   NaN  \n",
       "2  1.1.3.15         NaN                 NaN           NaN          NaN   NaN  \n",
       "3  1.1.3.15         NaN                 NaN           NaN          NaN   NaN  \n",
       "4  1.1.3.15         NaN                 NaN           NaN          NaN   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>taxid</th>\n",
       "      <th>organism</th>\n",
       "      <th>superkingdom</th>\n",
       "      <th>ph</th>\n",
       "      <th>temperature</th>\n",
       "      <th>pfam</th>\n",
       "      <th>ec</th>\n",
       "      <th>synthesized</th>\n",
       "      <th>substrate_available</th>\n",
       "      <th>total_soluble</th>\n",
       "      <th>total_active</th>\n",
       "      <th>batch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>B9REU4</td>\n",
       "      <td>3988.0</td>\n",
       "      <td>Ricinus communis</td>\n",
       "      <td>Eukaryota</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PF07250, PF09118</td>\n",
       "      <td>1.1.3.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2051</th>\n",
       "      <td>B9RYU4</td>\n",
       "      <td>3988.0</td>\n",
       "      <td>Ricinus communis</td>\n",
       "      <td>Eukaryota</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PF07250, PF09118</td>\n",
       "      <td>1.1.3.9</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>second</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2052</th>\n",
       "      <td>B9R845</td>\n",
       "      <td>3988.0</td>\n",
       "      <td>Ricinus communis</td>\n",
       "      <td>Eukaryota</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PF07250, PF09118</td>\n",
       "      <td>1.1.3.9</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2053</th>\n",
       "      <td>M5CRB8</td>\n",
       "      <td>1118156.0</td>\n",
       "      <td>Stenotrophomonas maltophilia</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>7.27</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1.3.9</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054</th>\n",
       "      <td>B8MB95</td>\n",
       "      <td>441959.0</td>\n",
       "      <td>Talaromyces stipitatus</td>\n",
       "      <td>Eukaryota</td>\n",
       "      <td>5.60</td>\n",
       "      <td>25.0</td>\n",
       "      <td>PF09118</td>\n",
       "      <td>1.1.3.9</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>second</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         uid      taxid                      organism superkingdom    ph  \\\n",
       "2050  B9REU4     3988.0              Ricinus communis    Eukaryota   NaN   \n",
       "2051  B9RYU4     3988.0              Ricinus communis    Eukaryota   NaN   \n",
       "2052  B9R845     3988.0              Ricinus communis    Eukaryota   NaN   \n",
       "2053  M5CRB8  1118156.0  Stenotrophomonas maltophilia     Bacteria  7.27   \n",
       "2054  B8MB95   441959.0        Talaromyces stipitatus    Eukaryota  5.60   \n",
       "\n",
       "      temperature              pfam       ec synthesized substrate_available  \\\n",
       "2050          NaN  PF07250, PF09118  1.1.3.9         NaN                 NaN   \n",
       "2051          NaN  PF07250, PF09118  1.1.3.9         Yes                 Yes   \n",
       "2052          NaN  PF07250, PF09118  1.1.3.9         Yes                 Yes   \n",
       "2053         30.0               NaN  1.1.3.9         Yes                 Yes   \n",
       "2054         25.0           PF09118  1.1.3.9         Yes                 Yes   \n",
       "\n",
       "     total_soluble total_active   batch  \n",
       "2050           NaN          NaN     NaN  \n",
       "2051            No          NaN  second  \n",
       "2052            No          NaN   first  \n",
       "2053            No          NaN   first  \n",
       "2054            No          NaN  second  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filepath = join(FINAL, 'experiments')\n",
    "\n",
    "batch1 = pd.read_csv(join(filepath, '1-1-3-n_batch1_summary.tsv'), sep='\\t')\n",
    "batch2 = pd.read_csv(join(filepath, '1-1-3-n_batch2_summary.tsv'), sep='\\t')\n",
    "\n",
    "# rename the column for the identifier\n",
    "batch1.rename(columns={'node':'uid'}, inplace=True)\n",
    "batch2.rename(columns={'name':'uid'}, inplace=True)\n",
    "\n",
    "# add info on which batch it is\n",
    "batch1['batch'] = 'first'\n",
    "batch2['batch'] = 'second'\n",
    "\n",
    "# check that there are no duplicates\n",
    "for uid in batch1.uid.values:\n",
    "    if uid in batch2.uid.values:\n",
    "        print('Bad overlap, uid %s exists in both datasets' % uid)\n",
    "    \n",
    "\n",
    "# combine them \n",
    "both_batches = batch1.append(batch2).drop_duplicates()\n",
    "\n",
    "# use True and False instead of Yes and No\n",
    "both_batches = both_batches.replace(True, 'Yes', regex=True)\n",
    "both_batches = both_batches.replace(False, 'No', regex=True)\n",
    "\n",
    "# drop unnessecary columns\n",
    "both_batches = both_batches[(both_batches['synthesized'] == 'Yes') |\n",
    "                            (both_batches['synthesized'] == 'No')]\n",
    "both_batches.drop(['rep1_soluble', \n",
    "                   'rep1_active', \n",
    "                   'rep2_soluble', \n",
    "                   'rep2_active', \n",
    "                   'rep3_soluble', \n",
    "                   'rep3_active'], axis=1, inplace=True)\n",
    "    \n",
    "display(both_batches.head())\n",
    "\n",
    "    \n",
    "# now merge with the other data\n",
    "uid_data = uid_data.merge(both_batches, on='uid', how='left')\n",
    "\n",
    "# replace empty strings with nans\n",
    "uid_data = uid_data.replace('', np.nan, regex=True)\n",
    "\n",
    "display(uid_data.head())\n",
    "display(uid_data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data on the substrate-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>taxid</th>\n",
       "      <th>organism</th>\n",
       "      <th>superkingdom</th>\n",
       "      <th>ph</th>\n",
       "      <th>temperature</th>\n",
       "      <th>pfam</th>\n",
       "      <th>ec</th>\n",
       "      <th>synthesized</th>\n",
       "      <th>substrate_available</th>\n",
       "      <th>total_soluble</th>\n",
       "      <th>total_active</th>\n",
       "      <th>batch</th>\n",
       "      <th>glycolate</th>\n",
       "      <th>lactate</th>\n",
       "      <th>2-hydroxyglutarate</th>\n",
       "      <th>2-hydroxyoctanoate</th>\n",
       "      <th>2-hydroxystearate</th>\n",
       "      <th>mandelate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q9LRS0</td>\n",
       "      <td>3702.0</td>\n",
       "      <td>Arabidopsis thaliana</td>\n",
       "      <td>Eukaryota</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1.3.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q9NYQ3</td>\n",
       "      <td>9606.0</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>Eukaryota</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1.3.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P37339</td>\n",
       "      <td>83333.0</td>\n",
       "      <td>Escherichia coli</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>7.01</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1.3.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q24JJ8</td>\n",
       "      <td>3702.0</td>\n",
       "      <td>Arabidopsis thaliana</td>\n",
       "      <td>Eukaryota</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1.3.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B8AUI3</td>\n",
       "      <td>39946.0</td>\n",
       "      <td>Oryza sativa</td>\n",
       "      <td>Eukaryota</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1.3.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      uid    taxid              organism superkingdom    ph  temperature pfam  \\\n",
       "0  Q9LRS0   3702.0  Arabidopsis thaliana    Eukaryota   NaN          NaN  NaN   \n",
       "1  Q9NYQ3   9606.0          Homo sapiens    Eukaryota   NaN          NaN  NaN   \n",
       "2  P37339  83333.0      Escherichia coli     Bacteria  7.01         36.0  NaN   \n",
       "3  Q24JJ8   3702.0  Arabidopsis thaliana    Eukaryota   NaN          NaN  NaN   \n",
       "4  B8AUI3  39946.0          Oryza sativa    Eukaryota   NaN          NaN  NaN   \n",
       "\n",
       "         ec synthesized substrate_available total_soluble total_active batch  \\\n",
       "0  1.1.3.15         NaN                 NaN           NaN          NaN   NaN   \n",
       "1  1.1.3.15         NaN                 NaN           NaN          NaN   NaN   \n",
       "2  1.1.3.15         NaN                 NaN           NaN          NaN   NaN   \n",
       "3  1.1.3.15         NaN                 NaN           NaN          NaN   NaN   \n",
       "4  1.1.3.15         NaN                 NaN           NaN          NaN   NaN   \n",
       "\n",
       "  glycolate lactate 2-hydroxyglutarate 2-hydroxyoctanoate 2-hydroxystearate  \\\n",
       "0       NaN     NaN                NaN                NaN               NaN   \n",
       "1       NaN     NaN                NaN                NaN               NaN   \n",
       "2       NaN     NaN                NaN                NaN               NaN   \n",
       "3       NaN     NaN                NaN                NaN               NaN   \n",
       "4       NaN     NaN                NaN                NaN               NaN   \n",
       "\n",
       "  mandelate  \n",
       "0       NaN  \n",
       "1       NaN  \n",
       "2       NaN  \n",
       "3       NaN  \n",
       "4       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>taxid</th>\n",
       "      <th>organism</th>\n",
       "      <th>superkingdom</th>\n",
       "      <th>ph</th>\n",
       "      <th>temperature</th>\n",
       "      <th>pfam</th>\n",
       "      <th>ec</th>\n",
       "      <th>synthesized</th>\n",
       "      <th>substrate_available</th>\n",
       "      <th>total_soluble</th>\n",
       "      <th>total_active</th>\n",
       "      <th>batch</th>\n",
       "      <th>glycolate</th>\n",
       "      <th>lactate</th>\n",
       "      <th>2-hydroxyglutarate</th>\n",
       "      <th>2-hydroxyoctanoate</th>\n",
       "      <th>2-hydroxystearate</th>\n",
       "      <th>mandelate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>D5MNA0</td>\n",
       "      <td>671143.0</td>\n",
       "      <td>Candidatus methylomirabilis</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1.3.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>A9QH69</td>\n",
       "      <td>1346.0</td>\n",
       "      <td>Streptococcus iniae</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>7.10</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1.3.15</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>first</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>A9QH71</td>\n",
       "      <td>1346.0</td>\n",
       "      <td>Streptococcus iniae</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>7.10</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1.3.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>Q9CG58</td>\n",
       "      <td>272623.0</td>\n",
       "      <td>Lactococcus lactis</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>7.04</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1.3.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>Q5SM78</td>\n",
       "      <td>300852.0</td>\n",
       "      <td>Thermus thermophilus</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>7.18</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1.3.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         uid     taxid                     organism superkingdom    ph  \\\n",
       "1406  D5MNA0  671143.0  Candidatus methylomirabilis     Bacteria   NaN   \n",
       "1407  A9QH69    1346.0          Streptococcus iniae     Bacteria  7.10   \n",
       "1408  A9QH71    1346.0          Streptococcus iniae     Bacteria  7.10   \n",
       "1409  Q9CG58  272623.0           Lactococcus lactis     Bacteria  7.04   \n",
       "1410  Q5SM78  300852.0         Thermus thermophilus     Bacteria  7.18   \n",
       "\n",
       "      temperature pfam        ec synthesized substrate_available  \\\n",
       "1406          NaN  NaN  1.1.3.15         NaN                 NaN   \n",
       "1407         37.0  NaN  1.1.3.15         Yes                 Yes   \n",
       "1408         37.0  NaN  1.1.3.15         NaN                 NaN   \n",
       "1409         31.0  NaN  1.1.3.15         NaN                 NaN   \n",
       "1410         71.0  NaN  1.1.3.15         NaN                 NaN   \n",
       "\n",
       "     total_soluble total_active  batch glycolate lactate 2-hydroxyglutarate  \\\n",
       "1406           NaN          NaN    NaN       NaN     NaN                NaN   \n",
       "1407           Yes          Yes  first       Yes     Yes                 No   \n",
       "1408           NaN          NaN    NaN       NaN     NaN                NaN   \n",
       "1409           NaN          NaN    NaN       NaN     NaN                NaN   \n",
       "1410           NaN          NaN    NaN       NaN     NaN                NaN   \n",
       "\n",
       "     2-hydroxyoctanoate 2-hydroxystearate mandelate  \n",
       "1406                NaN               NaN       NaN  \n",
       "1407                Yes               Yes        No  \n",
       "1408                NaN               NaN       NaN  \n",
       "1409                NaN               NaN       NaN  \n",
       "1410                NaN               NaN       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taxid</th>\n",
       "      <th>ph</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.258000e+03</td>\n",
       "      <td>811.000000</td>\n",
       "      <td>1036.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.496091e+05</td>\n",
       "      <td>7.024032</td>\n",
       "      <td>33.610039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.306286e+05</td>\n",
       "      <td>0.445190</td>\n",
       "      <td>7.201882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.950000e+02</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.020845e+05</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.666790e+05</td>\n",
       "      <td>7.010000</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.126095e+06</td>\n",
       "      <td>7.120000</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.835254e+06</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              taxid          ph  temperature\n",
       "count  1.258000e+03  811.000000  1036.000000\n",
       "mean   6.496091e+05    7.024032    33.610039\n",
       "std    5.306286e+05    0.445190     7.201882\n",
       "min    1.950000e+02    1.500000    10.000000\n",
       "25%    1.020845e+05    7.000000    29.000000\n",
       "50%    5.666790e+05    7.010000    36.000000\n",
       "75%    1.126095e+06    7.120000    36.000000\n",
       "max    1.835254e+06    9.000000    90.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1411, 19)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load up the data from both batches\n",
    "data1 = pd.read_csv(join(FINAL, 'experiments', '1.1.3.15_detailed_batch1.csv'), \n",
    "                    sep=';', \n",
    "                    index_col=None)\n",
    "data2 = pd.read_csv(join(FINAL, 'experiments', '1.1.3.15_detailed_batch2.csv'), \n",
    "                    sep=';', \n",
    "                    index_col=None)\n",
    "data = data1.append(data2)\n",
    "\n",
    "# change True to Yes and False to No\n",
    "data.replace(True, 'Yes', regex=False, inplace=True)\n",
    "data.replace(False, 'No', regex=False, inplace=True)\n",
    "\n",
    "# re-name protein column\n",
    "data.rename(columns={'protein':'uid'}, inplace=True)\n",
    "\n",
    "# combine with all the other data from 1.1.3.15\n",
    "uid_data_subset = uid_data[uid_data['ec']=='1.1.3.15']\n",
    "prop_data = uid_data_subset.merge(data, \n",
    "                     on='uid', \n",
    "                     how='left')\n",
    "\n",
    "display(prop_data.head())\n",
    "display(prop_data.tail())\n",
    "display(prop_data.describe())\n",
    "display(prop_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/Work/projects/sampling_1.1.3.15/data/raw_external/brenda_2019_2/html_data/1.1.3.15.html'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-75ab0c5d5371>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0min_brenda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all_uniprot_id_brenparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'1.1.3.15'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# BRENDA version 2019.1, all tables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-75ab0c5d5371>\u001b[0m in \u001b[0;36mget_all_uniprot_id_brenparse\u001b[0;34m(ec)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRAW_EXTERNAL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'brenda_2019_2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html_data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'{}.html'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0msoup_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_ec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0morgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOrganism\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/Work/software/brenparse/brenparse/parser.py\u001b[0m in \u001b[0;36mopen_ec\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mReturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0msoup\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     '''\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ISO-8859-1'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/Work/projects/sampling_1.1.3.15/data/raw_external/brenda_2019_2/html_data/1.1.3.15.html'"
     ]
    }
   ],
   "source": [
    "def get_all_uniprot_id(ec='1.1.3.15'):\n",
    "    '''\n",
    "    Use regex to get all the uniprot identifiers. \n",
    "    Intended as an alternate method that does not depend on parsing the html.\n",
    "    '''\n",
    "\n",
    "    #read the html page\n",
    "    filepath = join(RAW_EXTERNAL, 'brenda_2019_2', 'html_data', '{}.html'.format(ec))\n",
    "    with open(filepath, 'r') as f:\n",
    "        document = f.read()\n",
    "\n",
    "    #http://www.uniprot.org/help/accession_numbers\n",
    "    m = re.findall('([OPQ][0-9](?:[A-Z0-9]){3}[0-9])|([A-NR-Z][0-9](?:[A-Z][A-Z0-9]{2}[0-9]){1,2})', document)\n",
    "\n",
    "    uids = set([])\n",
    "    for result in m:\n",
    "        for uid in result:\n",
    "            if uid == '':\n",
    "                continue\n",
    "                \n",
    "            uids.add(uid)\n",
    "    return list(uids)\n",
    "\n",
    "\n",
    "\n",
    "def get_all_uniprot_id_brenparse(ec='1.1.3.15'):\n",
    "    '''\n",
    "    Parse an html file using the brenparse library.\n",
    "    This allows for parsing of specific tables. Here\n",
    "    the organism table is used.\n",
    "    '''\n",
    "\n",
    "    filepath = join(RAW_EXTERNAL, 'brenda_2019_2', 'html_data', '{}.html'.format(ec))\n",
    "\n",
    "    soup_obj = parser.open_ec(filepath)\n",
    "    orgs = parser.Organism(soup_obj)\n",
    "    \n",
    "    uids = []\n",
    "    for entry in orgs.get_data(uid_orgs_only=False).values():\n",
    "        uids.extend(entry)\n",
    "    return list(set(uids))\n",
    "    \n",
    "    \n",
    "\n",
    "in_brenda = get_all_uniprot_id_brenparse(ec='1.1.3.15') # BRENDA version 2019.1, all tables\n",
    "\n",
    "\n",
    "\n",
    "print(in_brenda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add information regarding which sequences are marked as characterized in BRENDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active = []\n",
    "for uid in in_brenda:\n",
    "    active.append('Yes')\n",
    "        \n",
    "brenda_df = pd.DataFrame({'uid':in_brenda, 'in_brenda':active})\n",
    "        \n",
    "\n",
    "# merge with data frame\n",
    "prop_data = prop_data.merge(brenda_df, on=['uid'], how='left')\n",
    "\n",
    "\n",
    "# replace nans\n",
    "prop_data.in_brenda = prop_data.in_brenda.replace(np.nan, 'No', regex=False)\n",
    "\n",
    "display(prop_data.head())\n",
    "display(prop_data.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add information regarding which sequences are marked as characterized in SwissProt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_swissprot = pd.read_csv(join(INTERMEDIATE, 'swissprot_2020_02', 'SwissProt-2020_02-protein-evidence.tsv'),\n",
    "                          sep='\\t')\n",
    "\n",
    "in_swissprot = in_swissprot[in_swissprot['ec']=='1.1.3.15'].uid.values\n",
    "\n",
    "active = []\n",
    "for uid in in_swissprot:\n",
    "    active.append('Yes')\n",
    "        \n",
    "swissprot_df = pd.DataFrame({'uid':in_swissprot, 'in_swissprot':active})\n",
    "        \n",
    "\n",
    "# merge with data frame\n",
    "prop_data = prop_data.merge(swissprot_df, on=['uid'], how='left')\n",
    "\n",
    "\n",
    "# replace nans\n",
    "prop_data.in_swissprot = prop_data.in_swissprot.replace(np.nan, 'No', regex=False)\n",
    "\n",
    "display(prop_data.head())\n",
    "display(prop_data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I also want to get data regarding which cluster the sequences are in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_dict = {k:None for k in prop_data.uid.values}\n",
    "\n",
    "filepath = join(FINAL, 'brenda_2017_1')\n",
    "\n",
    "for fi in os.listdir(filepath):\n",
    "    if fi.endswith('sequences.fasta'):\n",
    "        cluster = fi.replace('_sequences.fasta', '')\n",
    "        \n",
    "        with open(join(filepath, fi), 'r') as f:\n",
    "            for line in f:\n",
    "                if line.startswith('>'):\n",
    "                    uid = line.strip('>').split(';')[0]\n",
    "                    uid_dict[uid] = cluster\n",
    "                    \n",
    "data = {'uid':[], 'cluster':[]}\n",
    "for k,v in uid_dict.items():\n",
    "    data['uid'].append(k)\n",
    "    data['cluster'].append(v)\n",
    "            \n",
    "\n",
    "prop_data = prop_data.merge(pd.DataFrame(data), on='uid')\n",
    "    \n",
    "display(prop_data.head())\n",
    "display(prop_data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add information regarding the Pfam domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first drop the old pfam data\n",
    "prop_data = prop_data.drop('pfam', axis=1)\n",
    "\n",
    "# load up the other pfam data\n",
    "filepath = join(FINAL, 'brenda_2017_1', 'pfam_info_2017_1.tsv')\n",
    "pfam_df = pd.read_csv(filepath, sep='\\t')\n",
    "\n",
    "# replace nans\n",
    "pfam_df = pfam_df.replace(np.nan, '', regex=True)\n",
    "display(pfam_df.head())\n",
    "display(pfam_df.describe())\n",
    "\n",
    "# merge with data frame\n",
    "prop_data = prop_data.merge(pfam_df, on=['uid'], how='left')\n",
    "\n",
    "display(prop_data.head())\n",
    "display(prop_data.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add in data for how identical sequences are compared to the BRENDA ones OR the SwissProt ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load up the identity data\n",
    "df_ident = pd.read_csv(join(FINAL, 'brenda_2017_1', 'all_identity_matrix_ident.tsv'), \n",
    "                       sep='\\t', \n",
    "                      index_col=0)\n",
    "\n",
    "display(df_ident.head())\n",
    "\n",
    "\n",
    "# get a list of all the selected identifiers \n",
    "selected = prop_data[(prop_data.in_brenda == 'Yes') | (prop_data.in_swissprot == 'Yes')]\n",
    "\n",
    "# get a list with all the identifiers not selected\n",
    "not_selected = prop_data[(prop_data.in_brenda == 'No') & (prop_data.in_swissprot == 'No')]\n",
    "\n",
    "# make sure all the identifiers are present in the identity matrix\n",
    "for uid in selected.uid.values:\n",
    "    assert uid in df_ident.index, 'Error, %s not present in identity matrix' % uid\n",
    "\n",
    "for uid in not_selected.uid.values:\n",
    "    assert uid in df_ident.index, 'Error, %s not present in identity matrix' % uid\n",
    "\n",
    "    \n",
    "# make a subset of the identity matrix\n",
    "df_ident_selected = df_ident.loc[selected.uid.values]\n",
    "\n",
    "\n",
    "sim_data = {'uid':[], 'max_database_sim':[]}\n",
    "for uid in prop_data.uid.values:\n",
    "    sim_data['uid'].append(uid)\n",
    "    sim_data['max_database_sim'].append(max(df_ident_selected[uid].values))\n",
    "\n",
    "sim_data_df = pd.DataFrame(sim_data)\n",
    "display(sim_data_df.head())\n",
    "\n",
    "# merge with the other data\n",
    "prop_data = prop_data.merge(sim_data_df, on=['uid'])\n",
    "display(prop_data.head())\n",
    "display(prop_data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add in data for how identical sequences are compared to the active ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# get a list of all the selected identifiers \n",
    "selected = prop_data[prop_data.total_active == 'Yes']\n",
    "\n",
    "# get a list with all the identifiers not selected\n",
    "not_selected = prop_data[prop_data.total_active == 'No']\n",
    "\n",
    "# make sure all the identifiers are present in the identity matrix\n",
    "for uid in selected.uid.values:\n",
    "    assert uid in df_ident.index, 'Error, %s not present in identity matrix' % uid\n",
    "\n",
    "for uid in not_selected.uid.values:\n",
    "    assert uid in df_ident.index, 'Error, %s not present in identity matrix' % uid\n",
    "\n",
    "    \n",
    "# make a subset of the identity matrix\n",
    "df_ident_selected = df_ident.loc[selected.uid.values]\n",
    "\n",
    "\n",
    "sim_data = {'uid':[], 'max_active_sim':[]}\n",
    "for uid in prop_data.uid.values:\n",
    "    sim_data['uid'].append(uid)\n",
    "    sim_data['max_active_sim'].append(max(df_ident_selected[uid].values))\n",
    "\n",
    "sim_data_df = pd.DataFrame(sim_data)\n",
    "display(sim_data_df.head())\n",
    "\n",
    "# merge with the other data\n",
    "prop_data = prop_data.merge(sim_data_df, on=['uid'])\n",
    "display(prop_data.head())\n",
    "display(prop_data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add in data for how identical sequences are compared BRENDA + SwissProt + active ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prop_data['max_all_sim'] = prop_data[['max_database_sim', 'max_active_sim']].max(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicates from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the unirep df has the same identifiers as the property df\n",
    "df_unirep = df_unirep[df_unirep['uid'].isin(prop_data['uid'].values)].reset_index(drop=True)\n",
    "\n",
    "# find duplicated items\n",
    "dups = df_unirep.drop('uid', axis=1).duplicated()\n",
    "\n",
    "# get the identifiers of duplicates\n",
    "dup_ids = df_unirep[dups].uid.values\n",
    "\n",
    "# any of these in my selected sequences?\n",
    "display(set(prop_data[prop_data['synthesized'] == 'Yes'].uid.values) & set(dup_ids))\n",
    "\n",
    "# if not I can remove duplicates\n",
    "df_unirep_nodups = df_unirep.drop('uid', axis=1).drop_duplicates()\n",
    "\n",
    "# get the index of remaining and make subset\n",
    "df_unirep = df_unirep.loc[df_unirep_nodups.index.values]\n",
    "prop_data = prop_data[prop_data.uid.isin(df_unirep.uid.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just a sanity check that they are in the same order\n",
    "for i in range(len(prop_data.uid.values)):\n",
    "    assert(prop_data.uid.values[i]==df_unirep.uid.values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if all the superkingdom designations are ok\n",
    "prop_data[prop_data['superkingdom'].isnull()]\n",
    "\n",
    "# I've looked at these manually and they are all bacterial\n",
    "prop_data.loc[prop_data['superkingdom'].isnull(), 'superkingdom'] = 'Bacteria'\n",
    "\n",
    "# save to file, for future reference\n",
    "prop_data.to_csv(join(FINAL, 'brenda_2017_1', 'all_prop_data_for_figures.tsv'), \n",
    "                 index=False, \n",
    "                 sep='\\t',\n",
    "                 na_rep='NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unirep.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert UniRep data to matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a matrix\n",
    "plot_data = df_unirep.drop(['uid'], axis=1)\n",
    "plot_data = plot_data.values\n",
    "plot_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate an MDS visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_plot = MDS(n_components=2, \n",
    "#           random_state=42).fit_transform(plot_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup the colors I want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eukaryota = '#b15928'\n",
    "bacteria = '#cab2d6'\n",
    "archaea = '#6a3d9a'\n",
    "other = '#c8c8c8'\n",
    "\n",
    "\n",
    "arch_col = '#6a3d9a'\n",
    "bact_col = '#cab2d6'\n",
    "euk_col = '#b15928'\n",
    "other_col = '#cc9933'\n",
    "\n",
    "cluster0 = '#077084'\n",
    "cluster1 = '#06a1f7'\n",
    "cluster2 = '#8214a0'\n",
    "cluster3 = '#fa78fa'\n",
    "cluster4 = '#aa0a3c'\n",
    "cluster5 = '#fa7850'\n",
    "cluster6 = '#0ab45a'\n",
    "cluster7 = '#a0fa82'\n",
    "cluster8 = '#f0f032'\n",
    "cluster9 = '#fae6be'\n",
    "\n",
    "colors = (cluster0, cluster1, cluster2, cluster3, cluster4, cluster5, cluster6, cluster7, cluster8, cluster9)\n",
    "\n",
    "selected = '#069f73'\n",
    "insoluble = '#5b5b5b'\n",
    "inactive = '#e79f26'\n",
    "active = '#069f73'\n",
    "\n",
    "brenda = 'black'\n",
    "\n",
    "# set up some plotting parameters\n",
    "small_point = 3\n",
    "large_point = 6\n",
    "\n",
    "font_size = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at pfam domains\n",
    "display(prop_data[['pfam', 'uid']].groupby('pfam').count())\n",
    "\n",
    "# save to table\n",
    "prop_data[['pfam', 'uid']].groupby('pfam').count().reset_index().to_csv(join(FINAL, 'pfam_domain_count.tsv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_data[['superkingdom', 'uid']].groupby('superkingdom').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_data[['total_active', 'uid']].groupby('total_active').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm2inch(*tupl):\n",
    "    '''\n",
    "    https://stackoverflow.com/questions/14708695/specify-figure-size-in-centimeter-in-matplotlib\n",
    "    '''\n",
    "    inch = 2.54\n",
    "    if isinstance(tupl[0], tuple):\n",
    "        return tuple(i/inch for i in tupl[0])\n",
    "    else:\n",
    "        return tuple(i/inch for i in tupl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rug plot of the identities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.3.5\n",
      "1.1.3.6\n",
      "1.1.3.7\n",
      "1.1.3.8\n",
      "1.1.3.9\n",
      "1.1.3.10\n",
      "1.1.3.12\n",
      "1.1.3.13\n",
      "1.1.3.15\n",
      "1.1.3.17\n",
      "1.1.3.20\n",
      "1.1.3.21\n",
      "1.1.3.37\n",
      "1.1.3.38\n",
      "1.1.3.41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>active</th>\n",
       "      <th>ec</th>\n",
       "      <th>max_database_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A060V429</td>\n",
       "      <td>False</td>\n",
       "      <td>1.1.3.10</td>\n",
       "      <td>27.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A0C5CCL2</td>\n",
       "      <td>False</td>\n",
       "      <td>1.1.3.9</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P93762</td>\n",
       "      <td>True</td>\n",
       "      <td>1.1.3.5</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A069BCI2</td>\n",
       "      <td>False</td>\n",
       "      <td>1.1.3.6</td>\n",
       "      <td>42.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A075UVN3</td>\n",
       "      <td>True</td>\n",
       "      <td>1.1.3.6</td>\n",
       "      <td>60.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          uid  active        ec  max_database_sim\n",
       "0  A0A060V429   False  1.1.3.10              27.7\n",
       "1  A0A0C5CCL2   False   1.1.3.9              19.0\n",
       "2      P93762    True   1.1.3.5             100.0\n",
       "3  A0A069BCI2   False   1.1.3.6              42.6\n",
       "4  A0A075UVN3    True   1.1.3.6              60.4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>active</th>\n",
       "      <th>ec</th>\n",
       "      <th>max_database_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>H3REB4</td>\n",
       "      <td>False</td>\n",
       "      <td>1.1.3.37</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>A2QTA3</td>\n",
       "      <td>False</td>\n",
       "      <td>1.1.3.38</td>\n",
       "      <td>32.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>I4EYC0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.1.3.38</td>\n",
       "      <td>43.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>P56216</td>\n",
       "      <td>True</td>\n",
       "      <td>1.1.3.38</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>W6WK03</td>\n",
       "      <td>False</td>\n",
       "      <td>1.1.3.38</td>\n",
       "      <td>38.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid  active        ec  max_database_sim\n",
       "65  H3REB4   False  1.1.3.37              22.0\n",
       "66  A2QTA3   False  1.1.3.38              32.4\n",
       "67  I4EYC0    True  1.1.3.38              43.6\n",
       "68  P56216    True  1.1.3.38             100.0\n",
       "69  W6WK03   False  1.1.3.38              38.3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_database_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40.024286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>24.086784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>12.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>32.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>46.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       max_database_sim\n",
       "count         70.000000\n",
       "mean          40.024286\n",
       "std           24.086784\n",
       "min           12.600000\n",
       "25%           24.900000\n",
       "50%           32.500000\n",
       "75%           46.850000\n",
       "max          100.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# which EC numbers we have been working on\n",
    "ec_nums_tested = ['1.1.3.5', '1.1.3.6', '1.1.3.7', \n",
    "                  '1.1.3.8', '1.1.3.9', '1.1.3.10', '1.1.3.12', '1.1.3.13',\n",
    "                  '1.1.3.15', '1.1.3.17', '1.1.3.20', '1.1.3.21', \n",
    "                  '1.1.3.37', '1.1.3.38', '1.1.3.41']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# load up the activity for tested sequences\n",
    "other_ec_activity = pd.read_csv(join(INTERMEDIATE, 'experiments', '1-1-3-n_no_1-1-3-15_total_activity_EC.tsv'), sep='\\t')\n",
    "\n",
    "\n",
    "# load up the identity data\n",
    "df_ident = pd.read_csv(join(INTERMEDIATE, 'BRENDA_for_paper', 'alignment_similarity_matrix_characterized_seqs.tsv'), \n",
    "                       sep='\\t', \n",
    "                      index_col=0)\n",
    "\n",
    "# load up the swissprot data\n",
    "in_swissprot = pd.read_csv(join(INTERMEDIATE, 'swissprot_2020_02', 'SwissProt-2020_02-protein-evidence.tsv'),\n",
    "                      sep='\\t')\n",
    "\n",
    "# for each of the ec numbers check how similar our sequences are to the previously tested ones\n",
    "sims = []\n",
    "for ec in ec_nums_tested:\n",
    "    print(ec)\n",
    "    \n",
    "    # which identifiers are listed as characterized in brenda for this ec\n",
    "    in_brenda = get_all_uniprot_id_brenparse(ec=ec)\n",
    "    \n",
    "    # which identifiers are listed as characterized in swissprot for this ec\n",
    "    in_swissprot_ec = list(in_swissprot[in_swissprot['ec']==ec].uid.values)\n",
    "    \n",
    "    # combine databases\n",
    "    combined_db = list(set(in_brenda + in_swissprot_ec))\n",
    "    \n",
    "    # which identifiers have we tested for this ec\n",
    "    our_activity_uids = other_ec_activity[other_ec_activity.ec==ec].uid.values\n",
    "    \n",
    "    # make a subset of the identity matrix\n",
    "    df_ident_selected = df_ident.loc[our_activity_uids, combined_db]\n",
    "\n",
    "    sim_data = {'uid':[], 'max_database_sim':[]}\n",
    "    for uid in our_activity_uids:\n",
    "        sim_data['uid'].append(uid)\n",
    "\n",
    "        sim_data['max_database_sim'].append(max(df_ident_selected.loc[uid].values))\n",
    "\n",
    "    sim_data_df = pd.DataFrame(sim_data)\n",
    "    \n",
    "    sims.append(sim_data_df)\n",
    "\n",
    "# concatenate together the individual ec data frames\n",
    "other_sims = pd.concat(sims).reset_index(drop=True)\n",
    "\n",
    "# merge with activity data\n",
    "other_ec_activity = other_ec_activity.merge(other_sims, on='uid')\n",
    "\n",
    "display(other_ec_activity.head())\n",
    "display(other_ec_activity.tail())\n",
    "display(other_ec_activity.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a subset to get the sequences of interest\n",
    "df_subset = prop_data.loc[prop_data['synthesized']=='Yes']\n",
    "df_subset = df_subset.loc[prop_data['substrate_available']=='Yes']\n",
    "\n",
    "# set sequences not showing canonical 1.1.3.15 activity as not active \n",
    "df_subset.loc[(df_subset.uid.isin(['A0A0B2PSV8', 'B8MKR3', 'C4VMW0', 'C0XIJ3',\n",
    "                                    'C2K1F0', 'A9QH69', 'A4YVE0', 'E6SCX5',\n",
    "                                    'C9Y9E7', 'W6W585', 'B1HZY7', 'F4G5A4',\n",
    "                                    'B7RR92', 'A0A087D1R1'])==False) & (df_subset.total_active=='Yes'), \n",
    "                                    'total_active'] = 'No'\n",
    "\n",
    "\n",
    "\n",
    "df_subset_activity = df_subset[df_subset['total_active'].isin(['No', 'Yes'])]\n",
    "df_subset_activity = df_subset_activity[['uid', 'total_active', 'ec', 'max_database_sim']]\n",
    "df_subset_activity.columns = ['uid', 'active', 'ec', 'max_database_sim']\n",
    "\n",
    "# change how activity values are encoded\n",
    "df_subset_activity.replace('Yes', True, inplace=True)\n",
    "df_subset_activity.replace('No', False, inplace=True)\n",
    "\n",
    "\n",
    "display(df_subset_activity.head())\n",
    "display(df_subset_activity.tail())\n",
    "display(df_subset_activity.describe())\n",
    "\n",
    "\n",
    "# now combine together the 1.1.3.15 data with the other ec data\n",
    "combined_activity_data = pd.concat([other_ec_activity, df_subset_activity])\n",
    "                                   \n",
    "                                   \n",
    "display(combined_activity_data.head())\n",
    "display(combined_activity_data.tail())\n",
    "display(combined_activity_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the tested ec classes, get sequence similarity to those tested in BRENDA for all. (Thse have been clustered at 90% identity so it is not all of the sequences in the ec classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ec</th>\n",
       "      <th>organism</th>\n",
       "      <th>uid</th>\n",
       "      <th>domain</th>\n",
       "      <th>best_match</th>\n",
       "      <th>ktuple_dist</th>\n",
       "      <th>identity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>227066</th>\n",
       "      <td>1.1.3.10</td>\n",
       "      <td>Actinobacteria bacterium</td>\n",
       "      <td>A0A0N1GNK6</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>Q75ZP8</td>\n",
       "      <td>0.867</td>\n",
       "      <td>22.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227067</th>\n",
       "      <td>1.1.3.10</td>\n",
       "      <td>Arthrobacter sp</td>\n",
       "      <td>J7LVS7</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>Q7ZA32</td>\n",
       "      <td>0.860</td>\n",
       "      <td>21.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227068</th>\n",
       "      <td>1.1.3.10</td>\n",
       "      <td>Arthrobacter sp</td>\n",
       "      <td>J7LQA3</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>Q8J2V8</td>\n",
       "      <td>0.849</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227069</th>\n",
       "      <td>1.1.3.10</td>\n",
       "      <td>Emericella nidulans</td>\n",
       "      <td>Q5B2E9</td>\n",
       "      <td>Eukaryota</td>\n",
       "      <td>Q7ZA32</td>\n",
       "      <td>0.789</td>\n",
       "      <td>36.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227070</th>\n",
       "      <td>1.1.3.10</td>\n",
       "      <td>Frankia alni</td>\n",
       "      <td>Q0RGV3</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>Q8J2V8</td>\n",
       "      <td>0.840</td>\n",
       "      <td>32.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ec                  organism         uid     domain best_match  \\\n",
       "227066  1.1.3.10  Actinobacteria bacterium  A0A0N1GNK6   Bacteria     Q75ZP8   \n",
       "227067  1.1.3.10           Arthrobacter sp      J7LVS7   Bacteria     Q7ZA32   \n",
       "227068  1.1.3.10           Arthrobacter sp      J7LQA3   Bacteria     Q8J2V8   \n",
       "227069  1.1.3.10       Emericella nidulans      Q5B2E9  Eukaryota     Q7ZA32   \n",
       "227070  1.1.3.10              Frankia alni      Q0RGV3   Bacteria     Q8J2V8   \n",
       "\n",
       "        ktuple_dist  identity  \n",
       "227066        0.867      22.3  \n",
       "227067        0.860      21.7  \n",
       "227068        0.849      29.0  \n",
       "227069        0.789      36.3  \n",
       "227070        0.840      32.8  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ec</th>\n",
       "      <th>organism</th>\n",
       "      <th>uid</th>\n",
       "      <th>domain</th>\n",
       "      <th>best_match</th>\n",
       "      <th>ktuple_dist</th>\n",
       "      <th>identity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>229692</th>\n",
       "      <td>1.1.3.9</td>\n",
       "      <td>Streptomyces griseus</td>\n",
       "      <td>A0A2X2P863</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>E6PBN6</td>\n",
       "      <td>0.845</td>\n",
       "      <td>21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229693</th>\n",
       "      <td>1.1.3.9</td>\n",
       "      <td>Streptomyces noursei</td>\n",
       "      <td>A0A1B2GI44</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>V5NQ89</td>\n",
       "      <td>0.797</td>\n",
       "      <td>32.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229694</th>\n",
       "      <td>1.1.3.9</td>\n",
       "      <td>Talaromyces stipitatus</td>\n",
       "      <td>B8MB95</td>\n",
       "      <td>Eukaryota</td>\n",
       "      <td>A0A0U1YLU5</td>\n",
       "      <td>0.828</td>\n",
       "      <td>32.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229695</th>\n",
       "      <td>1.1.3.9</td>\n",
       "      <td>Variovorax paradoxus</td>\n",
       "      <td>C5CYJ5</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>A0A089QAB6</td>\n",
       "      <td>0.775</td>\n",
       "      <td>37.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229696</th>\n",
       "      <td>1.1.3.9</td>\n",
       "      <td>endosymbiont of</td>\n",
       "      <td>G2DAI4</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>P0CS93</td>\n",
       "      <td>0.914</td>\n",
       "      <td>10.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ec                organism         uid     domain  best_match  \\\n",
       "229692  1.1.3.9    Streptomyces griseus  A0A2X2P863   Bacteria      E6PBN6   \n",
       "229693  1.1.3.9    Streptomyces noursei  A0A1B2GI44   Bacteria      V5NQ89   \n",
       "229694  1.1.3.9  Talaromyces stipitatus      B8MB95  Eukaryota  A0A0U1YLU5   \n",
       "229695  1.1.3.9    Variovorax paradoxus      C5CYJ5   Bacteria  A0A089QAB6   \n",
       "229696  1.1.3.9         endosymbiont of      G2DAI4   Bacteria      P0CS93   \n",
       "\n",
       "        ktuple_dist  identity  \n",
       "229692        0.845      21.4  \n",
       "229693        0.797      32.1  \n",
       "229694        0.828      32.6  \n",
       "229695        0.775      37.4  \n",
       "229696        0.914      10.1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ktuple_dist</th>\n",
       "      <th>identity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2522.000000</td>\n",
       "      <td>2522.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.774001</td>\n",
       "      <td>33.626566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.215270</td>\n",
       "      <td>23.697254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.769000</td>\n",
       "      <td>15.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.845000</td>\n",
       "      <td>26.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.893000</td>\n",
       "      <td>43.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.986000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ktuple_dist     identity\n",
       "count  2522.000000  2522.000000\n",
       "mean      0.774001    33.626566\n",
       "std       0.215270    23.697254\n",
       "min       0.000000     2.700000\n",
       "25%       0.769000    15.500000\n",
       "50%       0.845000    26.600000\n",
       "75%       0.893000    43.600000\n",
       "max       0.986000   100.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filepath = join(INTERMEDIATE, 'BRENDA_for_paper', 'parsed_info', 'fasta_data_ec_uid_orgs_domain_2_kdist_aln.tsv')\n",
    "df_fasta = pd.read_csv(filepath, sep='\\t')\n",
    "\n",
    "\n",
    "df_fasta_tested = df_fasta[df_fasta['ec'].isin(ec_nums_tested)]\n",
    "\n",
    "display(df_fasta_tested.head())\n",
    "display(df_fasta_tested.tail())\n",
    "display(df_fasta_tested.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First try rug plot in matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# first plot all the sequences \n",
    "for i, ec in enumerate(ec_nums_tested[::-1]):\n",
    "    ax.plot(df_fasta_tested[df_fasta_tested['ec']==ec].identity.values, \n",
    "            [0.1*i]*len(df_fasta_tested[df_fasta_tested['ec']==ec].identity.values), \n",
    "            '|', ms=10, c=other, alpha=0.5)  # rug plot\n",
    "\n",
    "# plot the inactive ones\n",
    "for i, ec in enumerate(ec_nums_tested[::-1]):\n",
    "    inact_ids = combined_activity_data[(combined_activity_data['active']==False) & (combined_activity_data['ec']==ec)].max_database_sim\n",
    "    ax.plot(inact_ids, \n",
    "            [0.1*i]*len(inact_ids), \n",
    "            '|', ms=10, mew=1.25, c=inactive, alpha=1)  # rug plot\n",
    "    \n",
    "# plot the active ones\n",
    "for i, ec in enumerate(ec_nums_tested[::-1]):\n",
    "    act_ids = combined_activity_data[(combined_activity_data['active']==True) & (combined_activity_data['ec']==ec)].max_database_sim\n",
    "    ax.plot(act_ids, \n",
    "            [0.1*i]*len(act_ids), \n",
    "            '|', ms=10, mew=1.25, c=active, alpha=1)  # rug plot\n",
    "    \n",
    "# fix the y axis\n",
    "plt.yticks([0.1*i for i in range(len(ec_nums_tested))], ec_nums_tested[::-1])  # Set text labels and properties.\n",
    "\n",
    "plt.xlabel('Sequence identity with previously characterized (%)', fontsize=font_size)\n",
    "plt.ylabel('EC number', fontsize=font_size)\n",
    "plt.tick_params(labelsize=font_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split these up based on those that have the \"canonical\" domains an those that don't"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine 1.1.3.15 data with that of the other enzyme classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['max_database_sim'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-d8161b562a85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdf_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_subset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprop_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'substrate_available'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'Yes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdf_subset_activity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_subset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_subset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_active'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'No'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Yes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf_subset_activity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_subset_activity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'uid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'total_active'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ec'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max_database_sim'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mdf_subset_activity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'uid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'active'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ec'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max_database_sim'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2804\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2805\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2806\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2808\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1552\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1553\u001b[0m         )\n\u001b[1;32m   1554\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1643\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"loc\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['max_database_sim'] not in index\""
     ]
    }
   ],
   "source": [
    "# load up the pfam data\n",
    "filepath = join(FINAL, 'experiments', 'pfam_info_all.tsv')\n",
    "pfam_df = pd.read_csv(filepath, sep='\\t')\n",
    "\n",
    "# make a subset to get the sequences of interest\n",
    "df_subset = prop_data.loc[prop_data['synthesized']=='Yes']\n",
    "df_subset = df_subset.loc[prop_data['substrate_available']=='Yes']\n",
    "df_subset_activity = df_subset[df_subset['total_active'].isin(['No', 'Yes'])]\n",
    "df_subset_activity = df_subset_activity[['uid', 'total_active', 'ec', 'max_database_sim']]\n",
    "df_subset_activity.columns = ['uid', 'active', 'ec', 'max_database_sim']\n",
    "\n",
    "# change how activity values are encoded\n",
    "df_subset_activity.replace('Yes', True, inplace=True)\n",
    "df_subset_activity.replace('No', False, inplace=True)\n",
    "\n",
    "\n",
    "# display(df_subset_activity.head())\n",
    "# display(df_subset_activity.tail())\n",
    "# display(df_subset_activity.describe())\n",
    "\n",
    "\n",
    "# now combine together the 1.1.3.15 data with the other ec data\n",
    "combined_activity_data = pd.concat([other_ec_activity, df_subset_activity])\n",
    "                                   \n",
    "                                   \n",
    "display(combined_activity_data.head())\n",
    "display(combined_activity_data.tail())\n",
    "display(combined_activity_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add in domain data to the experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_activity_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-8335cefb5d98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcombined_activity_data_pfam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_activity_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpfam_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'uid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_activity_data_pfam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_activity_data_pfam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_activity_data_pfam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'combined_activity_data' is not defined"
     ]
    }
   ],
   "source": [
    "combined_activity_data_pfam = combined_activity_data.merge(pfam_df, on='uid')\n",
    "\n",
    "display(combined_activity_data_pfam.head())\n",
    "display(combined_activity_data_pfam.tail())\n",
    "display(combined_activity_data_pfam.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine which domains are canonical for each EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ec</th>\n",
       "      <th>uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1.3.9</td>\n",
       "      <td>P0CS93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1.3.15</td>\n",
       "      <td>Q9UJM8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.1.3.45</td>\n",
       "      <td>Q0PCD7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.1.3.47</td>\n",
       "      <td>E4QP00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.1.3.15</td>\n",
       "      <td>Q07523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ec     uid\n",
       "0   1.1.3.9  P0CS93\n",
       "1  1.1.3.15  Q9UJM8\n",
       "2  1.1.3.45  Q0PCD7\n",
       "3  1.1.3.47  E4QP00\n",
       "4  1.1.3.15  Q07523"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ec</th>\n",
       "      <th>uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>1.1.3.9</td>\n",
       "      <td>V5NQ89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>1.1.3.9</td>\n",
       "      <td>A0A089QAB6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>1.1.3.9</td>\n",
       "      <td>A0A0U1YLU5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1.1.3.9</td>\n",
       "      <td>E6PBN6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1.1.3.B4</td>\n",
       "      <td>T2M2J4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ec         uid\n",
       "154   1.1.3.9      V5NQ89\n",
       "155   1.1.3.9  A0A089QAB6\n",
       "156   1.1.3.9  A0A0U1YLU5\n",
       "157   1.1.3.9      E6PBN6\n",
       "158  1.1.3.B4      T2M2J4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ec</th>\n",
       "      <th>uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>28</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>1.1.3.13</td>\n",
       "      <td>A9QH69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ec     uid\n",
       "count        159     159\n",
       "unique        28     152\n",
       "top     1.1.3.13  A9QH69\n",
       "freq          29       2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load those marked as characterized in BRENDA\n",
    "brenda_df = pd.read_csv(join(INTERMEDIATE, 'BRENDA_for_paper', 'parsed_info', 'ec_data_uid_orgs.tsv'), sep='\\t')\n",
    "brenda_df = brenda_df[brenda_df['ec'].str.startswith('1.1.3.')].drop('organism', axis=1)\n",
    "\n",
    "# load those marked as characterized in SwissProt\n",
    "swissprot_df = pd.read_csv(join(INTERMEDIATE, 'swissprot_2020_02', 'SwissProt-2020_02-protein-evidence.tsv'), sep='\\t')\n",
    "swissprot_df = swissprot_df[swissprot_df['ec'].str.startswith('1.1.3.')].drop(['organism', 'organism_id'], axis=1)\n",
    "        \n",
    "# join the two data frames\n",
    "both_df = swissprot_df[['ec', 'uid']].append(brenda_df)\n",
    "both_df = both_df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "display(both_df.head())\n",
    "display(both_df.tail())\n",
    "display(both_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pfam</th>\n",
       "      <th>ec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PF00732,PF05199</td>\n",
       "      <td>1.1.3.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PF00732,PF05199</td>\n",
       "      <td>1.1.3.B4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PF01565</td>\n",
       "      <td>1.1.3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PF01070</td>\n",
       "      <td>1.1.3.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PF01565,PF04030</td>\n",
       "      <td>1.1.3.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pfam        ec\n",
       "0  PF00732,PF05199  1.1.3.13\n",
       "1  PF00732,PF05199  1.1.3.B4\n",
       "2          PF01565  1.1.3.42\n",
       "3          PF01070  1.1.3.46\n",
       "4  PF01565,PF04030  1.1.3.37"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pfam</th>\n",
       "      <th>ec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>PF00732,PF05199</td>\n",
       "      <td>1.1.3.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>PF00465</td>\n",
       "      <td>1.1.3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>PF00890,PF05199</td>\n",
       "      <td>1.1.3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>PF00732,PF05199</td>\n",
       "      <td>1.1.3.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>PF01266</td>\n",
       "      <td>1.1.3.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pfam        ec\n",
       "119  PF00732,PF05199  1.1.3.17\n",
       "128          PF00465  1.1.3.48\n",
       "133  PF00890,PF05199   1.1.3.6\n",
       "135  PF00732,PF05199  1.1.3.43\n",
       "155          PF01266  1.1.3.21"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pfam</th>\n",
       "      <th>ec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>17</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>PF00732,PF05199</td>\n",
       "      <td>1.1.3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   pfam       ec\n",
       "count                37       38\n",
       "unique               17       28\n",
       "top     PF00732,PF05199  1.1.3.6\n",
       "freq                 14        5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get all the unique combinactions of EC and pfam domains, these are considered the canonical ones\n",
    "canonical_df = pfam_df.merge(both_df, on='uid').drop('uid', axis=1)\n",
    "canonical_df = canonical_df.drop_duplicates()\n",
    "\n",
    "display(canonical_df.head())\n",
    "display(canonical_df.tail())\n",
    "display(canonical_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure out which sequences have the same pfam domains as those that are characterized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_activity_data_pfam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-1d04d8335e6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# instersect with experimental data to find which have canonical domain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcombined_activity_data_pfam_canonical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_activity_data_pfam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanonical_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pfam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ec'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_activity_data_pfam_canonical\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'combined_activity_data_pfam' is not defined"
     ]
    }
   ],
   "source": [
    "# add in extra column specificying that these ec domain combinations are canonical\n",
    "canonical_df.insert(len(canonical_df.columns), 'canonical', True)\n",
    "\n",
    "# instersect with experimental data to find which have canonical domain\n",
    "combined_activity_data_pfam_canonical = combined_activity_data_pfam.merge(canonical_df, on=['pfam', 'ec'], how='left').fillna(False)\n",
    "\n",
    "display(combined_activity_data_pfam_canonical.head())\n",
    "display(combined_activity_data_pfam_canonical.tail())\n",
    "display(combined_activity_data_pfam_canonical.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do the same for the fasta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the fasta data by dropping some columns\n",
    "df_fasta_tested_strip = df_fasta_tested.drop(['organism', 'domain', 'best_match', 'ktuple_dist'], axis=1)\n",
    "\n",
    "\n",
    "df_fasta_tested_strip_pfam = df_fasta_tested_strip.merge(pfam_df, on='uid')\n",
    "\n",
    "# instersect with fasta data to find which have canonical domain\n",
    "df_fasta_tested_strip_pfam_canonical = df_fasta_tested_strip_pfam.merge(canonical_df, on=['pfam', 'ec'], how='left').fillna(False)\n",
    "\n",
    "display(df_fasta_tested_strip_pfam_canonical.head())\n",
    "display(df_fasta_tested_strip_pfam_canonical.tail())\n",
    "display(df_fasta_tested_strip_pfam_canonical.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "combined_activity_data = combined_activity_data_pfam_canonical\n",
    "\n",
    "tick_length = 7\n",
    "tick_thick = 2\n",
    "\n",
    "\n",
    "# first plot all the sequences \n",
    "for i, ec in enumerate(ec_nums_tested[::-1]):\n",
    "    ax.plot(df_fasta_tested_strip_pfam_canonical[(df_fasta_tested_strip_pfam_canonical['ec']==ec) &\n",
    "                                                 (df_fasta_tested_strip_pfam_canonical['canonical']==True)].identity.values, \n",
    "            [0.1*i]*len(df_fasta_tested_strip_pfam_canonical[(df_fasta_tested_strip_pfam_canonical['ec']==ec) &\n",
    "                                                 (df_fasta_tested_strip_pfam_canonical['canonical']==True)].identity.values), \n",
    "            '|', ms=tick_length, mew=tick_thick, c=other, alpha=0.5)  # rug plot\n",
    "\n",
    "\n",
    "### canonical ###\n",
    "\n",
    "# plot the inactive ones with canonical domain\n",
    "for i, ec in enumerate(ec_nums_tested[::-1]):\n",
    "    for j, canonical in enumerate([True, False]):\n",
    "    \n",
    "        inact_ids = combined_activity_data[(combined_activity_data['active']==False) & \n",
    "                                           (combined_activity_data['ec']==ec) & \n",
    "                                           (combined_activity_data['canonical']==True)].max_database_sim\n",
    "        ax.plot(inact_ids, \n",
    "                [0.1*i]*len(inact_ids), \n",
    "                '|', ms=tick_length, mew=tick_thick, c=inactive, alpha=1)  # rug plot\n",
    "    \n",
    "# plot the active ones with canonical domain\n",
    "for i, ec in enumerate(ec_nums_tested[::-1]):\n",
    "    act_ids = combined_activity_data[(combined_activity_data['active']==True) & \n",
    "                                     (combined_activity_data['ec']==ec) & \n",
    "                                     (combined_activity_data['canonical']==True)].max_database_sim\n",
    "    ax.plot(act_ids, \n",
    "            [0.1*i]*len(act_ids), \n",
    "            '|', ms=tick_length, mew=tick_thick, c=active, alpha=1)  # rug plot\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "### non-canonical ###\n",
    "\n",
    "# first plot all the sequences \n",
    "for i, ec in enumerate(ec_nums_tested[::-1]):\n",
    "    ax.plot(df_fasta_tested_strip_pfam_canonical[(df_fasta_tested_strip_pfam_canonical['ec']==ec) &\n",
    "                                                 (df_fasta_tested_strip_pfam_canonical['canonical']==False)].identity.values, \n",
    "            [0.05+0.1*i]*len(df_fasta_tested_strip_pfam_canonical[(df_fasta_tested_strip_pfam_canonical['ec']==ec) &\n",
    "                                                 (df_fasta_tested_strip_pfam_canonical['canonical']==False)].identity.values), \n",
    "            '|', ms=tick_length, mew=tick_thick, c=other, alpha=0.5)  # rug plot\n",
    "    \n",
    "\n",
    "for i, ec in enumerate(ec_nums_tested[::-1]):\n",
    "    for j, canonical in enumerate([True, False]):\n",
    "    \n",
    "        inact_ids = combined_activity_data[(combined_activity_data['active']==False) & \n",
    "                                           (combined_activity_data['ec']==ec) & \n",
    "                                           (combined_activity_data['canonical']==False)].max_database_sim\n",
    "        ax.plot(inact_ids, \n",
    "                [0.05+0.1*i]*len(inact_ids), \n",
    "                '|', ms=tick_length, mew=tick_thick, c=inactive, alpha=1)  # rug plot\n",
    "    \n",
    "# plot the active ones\n",
    "for i, ec in enumerate(ec_nums_tested[::-1]):\n",
    "    act_ids = combined_activity_data[(combined_activity_data['active']==True) & \n",
    "                                     (combined_activity_data['ec']==ec) & \n",
    "                                     (combined_activity_data['canonical']==False)].max_database_sim\n",
    "    ax.plot(act_ids, \n",
    "            [0.05+0.1*i]*len(act_ids), \n",
    "            '|', ms=tick_length, mew=tick_thick, c=active, alpha=1)  # rug plot\n",
    "    \n",
    "    \n",
    "# fix the y axis\n",
    "labels = []\n",
    "ticks = []\n",
    "for i, ecnum in enumerate(ec_nums_tested[::-1]):\n",
    "    labels.append(ecnum + ' canonical')\n",
    "    labels.append(ecnum + ' non-canonical')\n",
    "    ticks.append(i*0.1)\n",
    "    ticks.append(0.05 + i*0.1)\n",
    "\n",
    "\n",
    "plt.yticks(ticks, labels)  # Set text labels and properties.\n",
    "\n",
    "plt.xlabel('Sequence identity with previously characterized (%)', fontsize=font_size)\n",
    "plt.ylabel('EC number', fontsize=font_size)\n",
    "plt.tick_params(labelsize=font_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try using seaborn instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.stripplot(x='max_database_sim', y='ec', data=combined_activity_data, \n",
    "              size=3, color=other, alpha=0.5, jitter=True)\n",
    "# sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# make a subset of the identity matrix\n",
    "df_ident_selected = df_ident.loc[other_ec_activity.uid]\n",
    "\n",
    "\n",
    "sim_data = {'uid':[], 'max_database_sim':[]}\n",
    "for uid in other_ec_activity.uid:\n",
    "    sim_data['uid'].append(uid)\n",
    "    sim_data['max_database_sim'].append(max(df_ident_selected[uid].values))\n",
    "\n",
    "sim_data_df = pd.DataFrame(sim_data)\n",
    "display(sim_data_df)\n",
    "\n",
    "\n",
    "#     # merge with the other data\n",
    "#     prop_data = prop_data.merge(sim_data_df, on=['uid'])\n",
    "#     display(prop_data.head())\n",
    "#     display(prop_data.tail())\n",
    "    \n",
    "    \n",
    "# add in the 1.1.3.15 data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ident = pd.read_csv(join(INTERMEDIATE, 'BRENDA_for_paper', 'alignment_similartity_matrix_characterized_seqs.tsv'), \n",
    "                       sep='\\t', \n",
    "                      index_col=0)\n",
    "\n",
    "df_ident.loc[list(df_fasta_tested.uid.values)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_ec_activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ident.loc[other_ec_activity.uid.values, in_brenda]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_ids = []\n",
    "\n",
    "with open(join(FINAL, 'brenda_2017_1', 'selected_ids.tsv'), 'r') as f:\n",
    "    ordered_ids.extend([s.rstrip() for s in f])\n",
    "    \n",
    "with open(join(FINAL, 'BRENDA_second_selection_swissprot', 'selected_ids.tsv'), 'r') as f:\n",
    "    ordered_ids.extend([s.rstrip() for s in f])\n",
    "    \n",
    "for uid in df_fasta_tested.uid.values:\n",
    "    if uid not in ordered_ids:\n",
    "        print(uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all identifiers with activity data\n",
    "all_ids = []\n",
    "\n",
    "all_ids.extend(df_subset[df_subset.total_active=='Yes'].uid)\n",
    "all_ids.extend(df_subset[df_subset.total_active=='No'].uid)\n",
    "all_ids.extend(other_ec_activity.uid)\n",
    "\n",
    "\n",
    "# collect all identifiers from fasta file\n",
    "fasta_ids = []\n",
    "with open(join(INTERMEDIATE, 'brenda_2019_2', '1_1_3__BRENDA_sequences_filtered_2019_2.fasta'), 'r') as f:\n",
    "    for line in f:\n",
    "        if line.startswith('>'):\n",
    "            fasta_ids.append(line.strip('>').split(';')[0])\n",
    "            \n",
    "            \n",
    "set(all_ids) - set(fasta_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fasta_tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_brenda = []\n",
    "for ec in ec_nums_tested:\n",
    "    in_brenda = get_all_uniprot_id_brenparse(ec=ec)\n",
    "    print(ec, in_brenda)\n",
    "    all_brenda.extend(in_brenda)\n",
    "\n",
    "\n",
    "for uid in all_brenda:\n",
    "    if uid not in df_fasta_tested.best_match.values:\n",
    "        print(uid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set([1,2])  set([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fasta_tested_subset = df_fasta_tested.loc[df_fasta_tested.uid.isin(all_brenda)]\n",
    "\n",
    "df_fasta_tested_subset = df_fasta_tested_subset.drop(['ec', 'organism', 'domain', 'best_match', 'ktuple_dist'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fasta_tested[df_fasta_tested.uid == 'B2MW81']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_ec_activity.merge(df_fasta_tested_subset, on='uid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_uid = []\n",
    "for record in SeqIO.parse(join(INTERMEDIATE, 'brenda_2019_2', '1_1_3__BRENDA_sequences_2019_2.fasta'), 'fasta'):\n",
    "    uid = record.description.split(';')[0]\n",
    "    seq = record.seq\n",
    "        \n",
    "    all_uid.append(uid)\n",
    "    \n",
    "\n",
    "for record in SeqIO.parse(join(INTERMEDIATE, 'brenda_2017_1', '1_1_3__BRENDA_sequences_2017_1.fasta'), 'fasta'):\n",
    "    uid = record.description.split(';')[0]\n",
    "    seq = record.seq\n",
    "\n",
    "    all_uid.append(uid)\n",
    "    \n",
    "    \n",
    "    \n",
    "all_brenda = []\n",
    "for ec in ec_nums_tested:\n",
    "    in_brenda = get_all_uniprot_id_brenparse(ec=ec)\n",
    "    \n",
    "    all_brenda.extend(in_brenda)\n",
    "\n",
    "\n",
    "for uid in all_brenda:\n",
    "    if uid not in all_uid:\n",
    "        print(uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_brenda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fasta_tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.loc[(df_subset.uid.isin(['A0A0B2PSV8', 'B8MKR3', 'C4VMW0', 'C0XIJ3',\n",
    "                                    'C2K1F0', 'A9QH69', 'A4YVE0', 'E6SCX5',\n",
    "                                    'C9Y9E7', 'W6W585', 'B1HZY7', 'F4G5A4',\n",
    "                                    'B7RR92', 'A0A087D1R1'])==False) & (df_subset.total_active=='No')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "df_unirep = load_unirep(uni_filepath=join(INTERMEDIATE, 'brenda_2017_1', '1_1_3__BRENDA_sequences_filtered_2017_1_unirep.csv'),\n",
    "                       prop_filepath=join(FINAL, 'brenda_2017_1', 'ec_uid_org_from_fasta_2017_1.tsv'),\n",
    "                       ec='all')\n",
    "    \n",
    "display(df_unirep.head())\n",
    "display(df_unirep.tail())\n",
    "display(df_unirep.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# make a matrix\n",
    "plot_data = df_unirep.drop(['uid'], axis=1)\n",
    "plot_data = plot_data.values\n",
    "plot_data\n",
    "\n",
    "my_plot = MDS(n_components=2, \n",
    "          random_state=42).fit_transform(plot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(my_plot[:,0], my_plot[:,1], s=5, color='grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show insoluble vs inactive vs active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we've modified the scoring of active enzymes to the numbers need to be updated in the prop_data df\n",
    "prop_data.loc[prop_data['total_active'] == 'Yes', 'total_active'] = 'No'\n",
    "prop_data.loc[prop_data['uid'].isin(both_batches.uid.values), 'total_active'] = 'Yes'\n",
    "\n",
    "\n",
    "# make the figure\n",
    "fig = plt.figure(figsize=(6, 3))\n",
    "\n",
    "\n",
    "#################\n",
    "## First panel ##\n",
    "#################\n",
    "\n",
    "\n",
    "# fourth plot, (insoluble, inactive, active, t-SNE plot)\n",
    "background = (prop_data.total_soluble != 'No') & (prop_data.total_active != 'No') & (prop_data.total_active != 'Yes')\n",
    "insol = prop_data.total_soluble == 'No'\n",
    "inact = (prop_data.total_soluble == 'Yes') & (prop_data.total_active == 'No')\n",
    "act = (prop_data.total_soluble == 'Yes') & (prop_data.total_active == 'Yes')\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(my_plot[:,0][background], my_plot[:,1][background], s=small_point, color=other)\n",
    "plt.scatter(my_plot[:,0][insol], my_plot[:,1][insol], s=large_point, color='#5b5b5b')\n",
    "plt.scatter(my_plot[:,0][inact], my_plot[:,1][inact], s=large_point, color=inactive)\n",
    "plt.scatter(my_plot[:,0][act], my_plot[:,1][act], s=large_point, color=active)\n",
    "#plt.gca().get_xaxis().set_ticklabels([])\n",
    "#plt.gca().get_yaxis().set_ticklabels([])\n",
    "plt.legend(['Not tested', 'Insoluble', 'Inactive', 'Active'], \n",
    "           fontsize=font_size,\n",
    "           loc='lower left',\n",
    "           bbox_to_anchor=(0, 1.02, 1, 0.2),\n",
    "           mode = 'expand',\n",
    "           ncol=2)\n",
    "\n",
    "plt.xlabel(None)\n",
    "plt.ylabel(None)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##################\n",
    "## Second panel ##\n",
    "##################\n",
    "\n",
    "# fifth plot (sequences per superkingdom, indicating soluble and insoluble fraction, stacked barchart)\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "# make a subset to get the sequences of interest\n",
    "df_subset = prop_data.loc[prop_data['synthesized']=='Yes']\n",
    "df_subset = df_subset.loc[prop_data['substrate_available']=='Yes']\n",
    "\n",
    "# count the frequencies\n",
    "df_temp = df_subset\n",
    "df_temp.total_active = df_temp.total_active.replace(np.nan, '', regex=True)\n",
    "result = df_temp.groupby('superkingdom')['total_active'].value_counts(normalize=True)\n",
    "result = result.unstack().fillna(0)\n",
    "result = result.reset_index()\n",
    "result.rename(index=str, columns={'No': 'Inactive', 'Yes': 'Active', '':'Insoluble'}, inplace=True)\n",
    "\n",
    "# count the total number per category\n",
    "result_count = df_temp.groupby('superkingdom')['uid'].nunique()\n",
    "result_count = pd.DataFrame(result_count)\n",
    "result_count = result_count.reset_index()\n",
    "result_count.rename(index=str, columns={'uid': 'count'}, inplace=True)\n",
    "\n",
    "# join the two \n",
    "result = result.merge(result_count, on='superkingdom')\n",
    "\n",
    "display(result)\n",
    "\n",
    "\n",
    "# now plot\n",
    "N = len(list(set(result.superkingdom)))\n",
    "insol = result.Insoluble.values\n",
    "inact = result.Inactive.values\n",
    "act = result.Active.values\n",
    "ind = np.arange(N)    # the x locations for the groups\n",
    "width = 0.5       # the width of the bars: can also be len(x) sequence\n",
    "\n",
    "p1 = plt.bar(ind, insol, width, \n",
    "            color='#5b5b5b')\n",
    "p2 = plt.bar(ind, inact, width,\n",
    "             bottom=insol, \n",
    "            color=inactive)\n",
    "p3 = plt.bar(ind, act, width,\n",
    "             bottom=insol+inact, \n",
    "            color=active)\n",
    "\n",
    "# add labels on top of bars\n",
    "for i, v in enumerate(result['count'].values):\n",
    "    plt.text(x=i-0.1, \n",
    "             y=1.01, \n",
    "             s=str(v), \n",
    "             color='black', \n",
    "             fontweight='normal',\n",
    "             fontsize=font_size)\n",
    "\n",
    "# tweak the axis\n",
    "plt.xticks(ind, result.superkingdom.values, rotation=45)\n",
    "plt.yticks(np.arange(0, 1.3, 0.2))\n",
    "plt.legend((p1[0], p2[0], p3[0]), ('Insoluble', 'Inactive', 'Active'),\n",
    "           fontsize=font_size,\n",
    "           loc='lower left',\n",
    "           bbox_to_anchor=(0, 1.02, 1, 0.2),\n",
    "           mode = 'expand',\n",
    "           ncol=2)\n",
    "plt.xlabel('Category', fontsize=font_size)\n",
    "plt.ylabel('Fraction', fontsize=font_size)\n",
    "plt.tick_params(labelsize=font_size)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.savefig(join(FIGURES, 'supplement_insoluble-soluble-active.png'), dpi=300, facecolor='w', edgecolor='w',\n",
    "        orientation='portrait', papertype=None, format=None,\n",
    "        transparent=False, bbox_inches=None, pad_inches=0.1, metadata=None)\n",
    "\n",
    "plt.savefig(join(FIGURES, 'supplement_insoluble-soluble-active.pdf'), facecolor='w', edgecolor='w',\n",
    "        orientation='portrait', papertype=None, format=None,\n",
    "        transparent=False, bbox_inches=None, pad_inches=0.1, metadata=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.groupby('superkingdom')['total_soluble'].value_counts(normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare identity between sequences with different domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot(1, 1, 1)\n",
    "\n",
    "\n",
    "# get the percentage identity data\n",
    "bins = list(range(0, 101, 1))\n",
    "sim_df = prop_data[['pfam', 'max_database_sim']]\n",
    "\n",
    "# replace low-n domains with \"Other\"\n",
    "domains = ['PF01070', 'PF01266', 'PF01266,PF04324', 'PF01565', 'PF01565,PF02913', 'PF02754']\n",
    "sim_df.loc[~sim_df['pfam'].isin(domains), 'pfam'] = translation['other']\n",
    "\n",
    "\n",
    "# translate the domain names \n",
    "sim_df.loc[sim_df['pfam'].isin(['PF01070']), 'pfam'] = translation['PF01070']\n",
    "sim_df.loc[sim_df['pfam'].isin(['PF01266']), 'pfam'] = translation['PF01266']\n",
    "sim_df.loc[sim_df['pfam'].isin(['PF01565']), 'pfam'] = translation['PF01565']\n",
    "sim_df.loc[sim_df['pfam'].isin(['PF01565,PF02913']), 'pfam'] = translation['PF01565,PF02913']\n",
    "sim_df.loc[sim_df['pfam'].isin(['PF01266,PF04324']), 'pfam'] = translation['PF01266,PF04324']\n",
    "sim_df.loc[sim_df['pfam'].isin(['PF02754']), 'pfam'] = translation['PF02754']\n",
    "\n",
    "groups = sim_df.groupby(['pfam', pd.cut(sim_df['max_database_sim'], bins=bins)])\n",
    "sim_df_bins = groups.size().unstack()\n",
    "\n",
    "my_bins = ['{}-{}'.format(s, s+1) for s in bins[:-1]]\n",
    "sim_df_bins.columns = my_bins\n",
    "\n",
    "# re-order rows\n",
    "sim_df_bins = sim_df_bins.reindex([translation[s] for s in domains] + ['Other'])\n",
    "\n",
    "# make the plot\n",
    "bar_l = range(sim_df_bins.shape[0])\n",
    "\n",
    "cm = plt.get_cmap('magma_r')\n",
    "\n",
    "ax.set_prop_cycle(cycler('color', [cm(1.*i/len(my_bins)) for i in range(len(my_bins))]))\n",
    "\n",
    "bottom = np.zeros_like(bar_l).astype('float')\n",
    "for i, deg in enumerate(my_bins):\n",
    "    ax.bar(bar_l, sim_df_bins[deg], \n",
    "               bottom=bottom, \n",
    "               label=deg,\n",
    "               linewidth=0)\n",
    "    bottom += sim_df_bins[deg].values\n",
    "\n",
    "ax.set_xticks(bar_l)\n",
    "ax.set_xticklabels(sim_df_bins.index, \n",
    "                       rotation=45, \n",
    "                       size=font_size,\n",
    "                       ha='right')\n",
    "\n",
    "# leg = ax.legend(loc=\"upper left\", \n",
    "#               bbox_to_anchor=(1, 1.05), \n",
    "#               ncol=1, \n",
    "#               fontsize=font_size)\n",
    "# leg.set_title('Max identity (%)', prop={'size':font_size})\n",
    "plt.ylabel('Sequences (#)', fontsize=font_size)\n",
    "plt.yticks(fontsize=font_size)\n",
    "\n",
    "cb = fig.colorbar(sc)\n",
    "cb.ax.tick_params(labelsize=font_size) \n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.savefig(join(FIGURES, 'supplement_stacked_identity_bar.png'), dpi=300, facecolor='w', edgecolor='w',\n",
    "        orientation='portrait', papertype=None, format=None,\n",
    "        transparent=False, bbox_inches=None, pad_inches=0.1, metadata=None)\n",
    "\n",
    "plt.savefig(join(FIGURES, 'supplement_stacked_identity_bar.pdf'), facecolor='w', edgecolor='w',\n",
    "        orientation='portrait', papertype=None, format=None,\n",
    "        transparent=False, bbox_inches=None, pad_inches=0.1, metadata=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing cluster belonging on the scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3, 3))\n",
    "\n",
    "\n",
    "plt.subplot(1, 1, 1)\n",
    "\n",
    "cluster_0 = prop_data.cluster == 'cluster_0'\n",
    "cluster_1 = prop_data.cluster == 'cluster_1'\n",
    "cluster_2 = prop_data.cluster == 'cluster_2'\n",
    "cluster_3 = prop_data.cluster == 'cluster_3'\n",
    "cluster_4 = prop_data.cluster == 'cluster_4'\n",
    "cluster_5 = prop_data.cluster == 'cluster_5'\n",
    "cluster_6 = prop_data.cluster == 'cluster_6'\n",
    "cluster_7 = prop_data.cluster == 'cluster_7'\n",
    "cluster_8 = prop_data.cluster == 'cluster_8'\n",
    "cluster_9 = prop_data.cluster == 'cluster_9'\n",
    "\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.scatter(my_plot[:,0][cluster_0], my_plot[:,1][cluster_0], s=small_point, color=cluster0)\n",
    "plt.scatter(my_plot[:,0][cluster_1], my_plot[:,1][cluster_1], s=small_point, color=cluster1)\n",
    "plt.scatter(my_plot[:,0][cluster_2], my_plot[:,1][cluster_2], s=small_point, color=cluster2)\n",
    "plt.scatter(my_plot[:,0][cluster_3], my_plot[:,1][cluster_3], s=small_point, color=cluster3)\n",
    "plt.scatter(my_plot[:,0][cluster_4], my_plot[:,1][cluster_4], s=small_point, color=cluster4)\n",
    "plt.scatter(my_plot[:,0][cluster_5], my_plot[:,1][cluster_5], s=small_point, color=cluster5)\n",
    "plt.scatter(my_plot[:,0][cluster_6], my_plot[:,1][cluster_6], s=small_point, color=cluster6)\n",
    "plt.scatter(my_plot[:,0][cluster_7], my_plot[:,1][cluster_7], s=small_point, color=cluster7)\n",
    "plt.scatter(my_plot[:,0][cluster_8], my_plot[:,1][cluster_8], s=small_point, color=cluster8)\n",
    "plt.scatter(my_plot[:,0][cluster_9], my_plot[:,1][cluster_9], s=small_point, color=cluster9)\n",
    "#plt.gca().get_xaxis().set_ticklabels([])\n",
    "#plt.gca().get_yaxis().set_ticklabels([])\n",
    "plt.legend(['Cluster 0', 'Cluster 1', \n",
    "            'Cluster 2', 'Cluster 3', \n",
    "            'Cluster 4', 'Cluster 5',\n",
    "            'Cluster 6', 'Cluster 7', \n",
    "            'Cluster 8', 'Cluster 9'], \n",
    "           fontsize=font_size,\n",
    "           loc='lower left',\n",
    "           bbox_to_anchor=(0, 1.02, 1, 0.2),\n",
    "           mode = 'expand',\n",
    "           ncol=2)\n",
    "\n",
    "plt.xlabel(None)\n",
    "plt.ylabel(None)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.savefig(join(FIGURES, 'supplement_scatterplot_of_clusters.png'), dpi=300, facecolor='w', edgecolor='w',\n",
    "        orientation='portrait', papertype=None, format=None,\n",
    "        transparent=False, bbox_inches=None, pad_inches=0.1, metadata=None)\n",
    "\n",
    "\n",
    "plt.savefig(join(FIGURES, 'supplement_scatterplot_of_clusters.pdf'), facecolor='w', edgecolor='w',\n",
    "        orientation='portrait', papertype=None, format=None,\n",
    "        transparent=False, bbox_inches=None, pad_inches=0.1, metadata=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supplementary Figure: Histogram of identities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(6, 3))\n",
    "\n",
    "\n",
    "# histogram before our characterization\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "plt.hist(prop_data.max_database_sim, \n",
    "         bins=10, \n",
    "         range=(0, 100),\n",
    "         color='black')  # arguments are passed to np.histogram\n",
    "\n",
    "\n",
    "# tweak the axis\n",
    "plt.ylabel('Count', fontsize=font_size)\n",
    "plt.xlabel('Bins', fontsize=font_size)\n",
    "plt.tick_params(labelsize=font_size)\n",
    "\n",
    "\n",
    "\n",
    "# histogram after our characterization\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "plt.hist(prop_data.max_all_sim, \n",
    "         bins=10, \n",
    "         range=(0, 100),\n",
    "         color='black')  # arguments are passed to np.histogram\n",
    "\n",
    "\n",
    "# tweak the axis\n",
    "plt.ylabel('Count', fontsize=font_size)\n",
    "plt.xlabel('Bins', fontsize=font_size)\n",
    "plt.tick_params(labelsize=font_size)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(join(FIGURES, 'supplemental_figure_histogram.png'), dpi=300, facecolor='w', edgecolor='w',\n",
    "        orientation='portrait', papertype=None, format=None,\n",
    "        transparent=False, bbox_inches=None, pad_inches=0.1, metadata=None)\n",
    "\n",
    "plt.savefig(join(FIGURES, 'supplemental_figure_histogram.pdf'), facecolor='w', edgecolor='w',\n",
    "        orientation='portrait', papertype=None, format=None,\n",
    "        transparent=False, bbox_inches=None, pad_inches=0.1 metadata=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old code. No longer used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supplementary Figure tested sequences per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(3, 3))\n",
    "\n",
    "\n",
    "\n",
    "# plt.subplot(1, 1, 1)\n",
    "\n",
    "# # count the frequencies\n",
    "# df_temp = df_subset\n",
    "# df_temp.total_active = df_temp.total_active.replace(np.nan, '', regex=True)\n",
    "# result = df_temp.groupby('cluster')['total_active'].value_counts(normalize=True)\n",
    "# result = result.unstack().fillna(0)\n",
    "# result = result.reset_index()\n",
    "# result.rename(index=str, columns={'No': 'Inactive', 'Yes': 'Active', '':'Insoluble'}, inplace=True)\n",
    "\n",
    "# # count the total number per category\n",
    "# result_count = df_subset.groupby('cluster')['uid'].nunique()\n",
    "# result_count = pd.DataFrame(result_count)\n",
    "# result_count = result_count.reset_index()\n",
    "# result_count.rename(index=str, columns={'uid': 'count'}, inplace=True)\n",
    "\n",
    "# # join the two \n",
    "# result = result.merge(result_count, on='cluster')\n",
    "\n",
    "# display(result)\n",
    "\n",
    "\n",
    "# # now plot\n",
    "# N = len(list(set(result.cluster)))\n",
    "# insol = result.Insoluble.values\n",
    "# inact = result.Inactive.values\n",
    "# act = result.Active.values\n",
    "# ind = np.arange(N)    # the x locations for the groups\n",
    "# width = 0.5       # the width of the bars: can also be len(x) sequence\n",
    "\n",
    "# p1 = plt.bar(ind, insol, width, \n",
    "#             color=insoluble)\n",
    "# p2 = plt.bar(ind, inact, width,\n",
    "#              bottom=insol, \n",
    "#             color=inactive)\n",
    "# p3 = plt.bar(ind, act, width,\n",
    "#              bottom=insol+inact, \n",
    "#             color=active)\n",
    "\n",
    "# # add labels on top of bars\n",
    "# for i, v in enumerate(result['count'].values):\n",
    "#     plt.text(x=i-0.1, \n",
    "#              y=1.01, \n",
    "#              s=str(v), \n",
    "#              color='black', \n",
    "#              fontweight='normal',\n",
    "#              fontsize=font_size)\n",
    "\n",
    "# # tweak the axis\n",
    "# plt.ylabel('Fraction')\n",
    "# plt.xticks(ind, result.cluster.values, rotation=45)\n",
    "# plt.yticks(np.arange(0, 1.3, 0.2))\n",
    "# plt.legend((p1[0], p2[0], p3[0]), ('Insoluble', 'Inactive', 'Active'),\n",
    "#            fontsize=font_size,\n",
    "#            loc='lower left',\n",
    "#            bbox_to_anchor=(0, 1.02, 1, 0.2),\n",
    "#            mode = 'expand',\n",
    "#            ncol=2)\n",
    "# plt.xlabel('Category', fontsize=font_size)\n",
    "# plt.ylabel('Fraction', fontsize=font_size)\n",
    "# plt.tick_params(labelsize=font_size)\n",
    "\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "\n",
    "# plt.savefig(join(FIGURES, 'supplemental_figure_tested_per_cluster.png'), dpi=300, facecolor='w', edgecolor='w',\n",
    "#         orientation='portrait', papertype=None, format=None,\n",
    "#         transparent=False, bbox_inches=None, pad_inches=0.1,\n",
    "#         frameon=None, metadata=None)\n",
    "\n",
    "\n",
    "# plt.savefig(join(FIGURES, 'supplemental_figure_tested_per_cluster.pdf'), facecolor='w', edgecolor='w',\n",
    "#         orientation='portrait', papertype=None, format=None,\n",
    "#         transparent=False, bbox_inches=None, pad_inches=0.1,\n",
    "#         frameon=None, metadata=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supplementary Figure: Mutual information per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqsample.seqsample import mi_for_selection\n",
    "\n",
    "fig = plt.figure(figsize=(6, 3))\n",
    "\n",
    "# before our work\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "\n",
    "# first I need to get the data\n",
    "data = {'cluster':[], 'brenda_mi':[], 'count':[]}\n",
    "\n",
    "clusters = list(set(prop_data.cluster.values))\n",
    "for clust in sorted(clusters):\n",
    "    # first subset that cluster\n",
    "    cluster_data = prop_data[prop_data.cluster == clust]\n",
    "    \n",
    "    # count the sequences\n",
    "    num_seq = len(cluster_data.uid.values)\n",
    "    \n",
    "    # now get identifiers in that cluster\n",
    "    selected = cluster_data[cluster_data.in_brenda == 'Yes'].uid.values\n",
    "    \n",
    "    # compute mutual information\n",
    "    filepath = join(FINAL, 'BRENDA', '%s_alignment.fasta' % clust)\n",
    "    mi = mi_for_selection(alignment_path=filepath, preselected=selected, unwanted=[])\n",
    "    \n",
    "    # add to data structure\n",
    "    data['cluster'].append(clust)\n",
    "    data['count'].append(num_seq)\n",
    "    data['brenda_mi'].append(mi)\n",
    "    \n",
    "result = pd.DataFrame(data)\n",
    "display(result)\n",
    "\n",
    "\n",
    "# now make the plot\n",
    "N = len(list(set(result.cluster)))\n",
    "mi_data = result.brenda_mi.values\n",
    "ind = np.arange(N)    # the x locations for the groups\n",
    "width = 0.5       # the width of the bars: can also be len(x) sequence\n",
    "\n",
    "p1 = plt.bar(ind, mi_data, width, \n",
    "            color=colors)\n",
    "\n",
    "# add labels on top of bars\n",
    "for i, v in enumerate(result['count'].values):\n",
    "    plt.text(x=i-0.1, \n",
    "             y=mi_data[i]+max(mi_data)*0.05, \n",
    "             s=str(v), \n",
    "             color='black', \n",
    "             fontweight='normal',\n",
    "             fontsize=font_size)\n",
    "\n",
    "    \n",
    "# tweak the axis\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(ind, result.cluster.values, rotation=45)\n",
    "plt.yticks(np.arange(0, 100, 20))\n",
    "plt.xlabel('Category', fontsize=font_size)\n",
    "plt.ylabel('Mutual information explained (%)', fontsize=font_size)\n",
    "plt.tick_params(labelsize=font_size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# after our work\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "\n",
    "# first I need to get the data\n",
    "data = {'cluster':[], 'active_mi':[], 'count':[]}\n",
    "\n",
    "clusters = list(set(prop_data.cluster.values))\n",
    "for clust in sorted(clusters):\n",
    "    # first subset that cluster\n",
    "    cluster_data = prop_data[prop_data.cluster == clust]\n",
    "    \n",
    "    # count the sequences\n",
    "    num_seq = len(cluster_data.uid.values)\n",
    "    \n",
    "    # now get identifiers in that cluster\n",
    "    selected = cluster_data[cluster_data.total_active == 'Yes'].uid.values\n",
    "    \n",
    "    # compute mutual information\n",
    "    filepath = join(FINAL, 'BRENDA', '%s_alignment.fasta' % clust)\n",
    "    mi = mi_for_selection(alignment_path=filepath, preselected=selected, unwanted=[])\n",
    "    \n",
    "    # add to data structure\n",
    "    data['cluster'].append(clust)\n",
    "    data['count'].append(num_seq)\n",
    "    data['active_mi'].append(mi)\n",
    "    \n",
    "result = pd.DataFrame(data)\n",
    "display(result)\n",
    "\n",
    "\n",
    "# now make the plot\n",
    "N = len(list(set(result.cluster)))\n",
    "mi_data = result.active_mi.values\n",
    "ind = np.arange(N)    # the x locations for the groups\n",
    "width = 0.5       # the width of the bars: can also be len(x) sequence\n",
    "\n",
    "p1 = plt.bar(ind, mi_data, width, \n",
    "            color=colors)\n",
    "\n",
    "# add labels on top of bars\n",
    "for i, v in enumerate(result['count'].values):\n",
    "    plt.text(x=i-0.1, \n",
    "             y=mi_data[i]+max(mi_data)*0.05, \n",
    "             s=str(v), \n",
    "             color='black', \n",
    "             fontweight='normal',\n",
    "             fontsize=font_size)\n",
    "\n",
    "# tweak the axis\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(ind, result.cluster.values, rotation=45)\n",
    "plt.yticks(np.arange(0, 100, 20))\n",
    "plt.xlabel('Category', fontsize=font_size)\n",
    "plt.ylabel('Mutual information explained (%)', fontsize=font_size)\n",
    "plt.tick_params(labelsize=font_size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(join(FIGURES, 'supplemental_figure_mutual_information.png'), dpi=300, facecolor='w', edgecolor='w',\n",
    "        orientation='portrait', papertype=None, format=None,\n",
    "        transparent=False, bbox_inches=None, pad_inches=0.1,\n",
    "        frameon=None, metadata=None)\n",
    "\n",
    "plt.savefig(join(FIGURES, 'supplemental_figure_mutual_information.pdf'), facecolor='w', edgecolor='w',\n",
    "        orientation='portrait', papertype=None, format=None,\n",
    "        transparent=False, bbox_inches=None, pad_inches=0.1,\n",
    "        frameon=None, metadata=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(9, 6))\n",
    "\n",
    "xlab = 'Dimension 1'\n",
    "ylab = 'Dimension 2'\n",
    "\n",
    "\n",
    "\n",
    "# first plot (characterized)\n",
    "background = prop_data.in_brenda.values == 'No'\n",
    "bren = prop_data.in_brenda == 'Yes'\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.scatter(my_plot[:,0][background], my_plot[:,1][background], s=small_point, color=other)\n",
    "plt.scatter(my_plot[:,0][bren], my_plot[:,1][bren], s=large_point, color=brenda)\n",
    "#plt.gca().get_xaxis().set_ticklabels([])\n",
    "#plt.gca().get_yaxis().set_ticklabels([])\n",
    "plt.legend(['Not tested', 'BRENDA'], \n",
    "           fontsize=font_size,\n",
    "           loc='lower left',\n",
    "           bbox_to_anchor=(0, 1.02, 1, 0.2),\n",
    "           mode = 'expand',\n",
    "           ncol=2)\n",
    "plt.xlabel(xlab,fontsize=font_size)\n",
    "plt.ylabel(ylab,fontsize=font_size)\n",
    "plt.tick_params(labelsize=font_size)\n",
    "\n",
    "\n",
    "\n",
    "# second plot (domain info)\n",
    "PF01070 = [True if 'PF01070' in s else False for s in  prop_data.pfam.values] # PF01070, FMN dehydrogenase\n",
    "PF01266 = [True if 'PF01266' in s else False for s in  prop_data.pfam.values] # PF01266, FAD dependent oxidoreductase family\n",
    "PF02754 = [True if 'PF02754' in s else False for s in  prop_data.pfam.values] # PF02754, Cys-rich-dom\n",
    "PF01565 = [True if 'PF01565' in s else False for s in  prop_data.pfam.values] # PF01565, FAD_binding_4\n",
    "background = [not any(s) for s in zip(PF01266, PF01070, PF02754, PF01565)]\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.scatter(my_plot[:,0][background], my_plot[:,1][background], s=small_point, color=other)\n",
    "plt.scatter(my_plot[:,0][PF01070], my_plot[:,1][PF01070], s=small_point, color=cluster3)\n",
    "plt.scatter(my_plot[:,0][PF01266], my_plot[:,1][PF01266], s=small_point, color=cluster1)\n",
    "plt.scatter(my_plot[:,0][PF02754], my_plot[:,1][PF02754], s=small_point, color=cluster4)\n",
    "plt.scatter(my_plot[:,0][PF01565], my_plot[:,1][PF01565], s=small_point, color=cluster5)\n",
    "#plt.gca().get_xaxis().set_ticklabels([])\n",
    "#plt.gca().get_yaxis().set_ticklabels([])\n",
    "plt.legend(['No domain', 'FMN-dh', 'FAD-oxred', 'Cys-rich-dom', 'FAD-binding'], \n",
    "           fontsize=font_size,\n",
    "           loc='lower left',\n",
    "           bbox_to_anchor=(0, 1.02, 1, 0.2),\n",
    "           mode = 'expand',\n",
    "           ncol=2)\n",
    "plt.xlabel(xlab,fontsize=font_size)\n",
    "plt.ylabel(ylab,fontsize=font_size)\n",
    "plt.tick_params(labelsize=font_size)\n",
    "\n",
    "\n",
    "\n",
    "# third plot (SwissProt identity t-SNE)\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "\n",
    "sort_mask = np.argsort(prop_data.max_database_sim.values)\n",
    "\n",
    "sc = plt.scatter(my_plot[:,0][sort_mask], my_plot[:,1][sort_mask], \n",
    "                 s=small_point, \n",
    "                 c=prop_data.max_database_sim.values[sort_mask], \n",
    "                 cmap='magma_r', # low contrast: 'viridis' 'plasma' high contrast: 'inferno' 'magma'\n",
    "                 vmin=0,\n",
    "                 vmax=100)\n",
    "#plt.gca().get_xaxis().set_ticklabels([])\n",
    "#plt.gca().get_yaxis().set_ticklabels([])\n",
    "plt.xlabel('Dimension 1',fontsize=font_size)\n",
    "plt.ylabel('Dimension 2',fontsize=font_size)\n",
    "cb = fig.colorbar(sc)\n",
    "cb.ax.tick_params(labelsize=font_size) \n",
    "plt.tick_params(labelsize=font_size)\n",
    "\n",
    "\n",
    "\n",
    "# fourth plot, (insoluble, inactive, active, t-SNE plot)\n",
    "background = (prop_data.total_soluble != 'No') & (prop_data.total_active != 'No') & (prop_data.total_active != 'Yes')\n",
    "insol = prop_data.total_soluble == 'No'\n",
    "inact = (prop_data.total_soluble == 'Yes') & (prop_data.total_active == 'No')\n",
    "act = (prop_data.total_soluble == 'Yes') & (prop_data.total_active == 'Yes')\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.scatter(my_plot[:,0][background], my_plot[:,1][background], s=small_point, color=other)\n",
    "plt.scatter(my_plot[:,0][insol], my_plot[:,1][insol], s=large_point, color=insoluble)\n",
    "plt.scatter(my_plot[:,0][inact], my_plot[:,1][inact], s=large_point, color=inactive)\n",
    "plt.scatter(my_plot[:,0][act], my_plot[:,1][act], s=large_point, color=active)\n",
    "#plt.gca().get_xaxis().set_ticklabels([])\n",
    "#plt.gca().get_yaxis().set_ticklabels([])\n",
    "plt.legend(['Not tested', 'Insoluble', 'Inactive', 'Active'], \n",
    "           fontsize=font_size,\n",
    "           loc='lower left',\n",
    "           bbox_to_anchor=(0, 1.02, 1, 0.2),\n",
    "           mode = 'expand',\n",
    "           ncol=2)\n",
    "plt.xlabel('Dimension 1', fontsize=font_size)\n",
    "plt.ylabel('Dimension 2', fontsize=font_size)\n",
    "plt.tick_params(labelsize=font_size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fifth plot (sequences per superkingdom, indicating soluble and insoluble fraction, stacked barchart)\n",
    "plt.subplot(2, 3, 5)\n",
    "\n",
    "# make a subset to get the sequences of interest\n",
    "df_subset = prop_data.loc[prop_data['synthesized']=='Yes']\n",
    "df_subset = df_subset.loc[prop_data['substrate_available']=='Yes']\n",
    "\n",
    "# count the frequencies\n",
    "df_temp = df_subset\n",
    "df_temp.total_active = df_temp.total_active.replace(np.nan, '', regex=True)\n",
    "result = df_temp.groupby('superkingdom')['total_active'].value_counts(normalize=True)\n",
    "result = result.unstack().fillna(0)\n",
    "result = result.reset_index()\n",
    "result.rename(index=str, columns={'No': 'Inactive', 'Yes': 'Active', '':'Insoluble'}, inplace=True)\n",
    "\n",
    "# count the total number per category\n",
    "result_count = df_temp.groupby('superkingdom')['uid'].nunique()\n",
    "result_count = pd.DataFrame(result_count)\n",
    "result_count = result_count.reset_index()\n",
    "result_count.rename(index=str, columns={'uid': 'count'}, inplace=True)\n",
    "\n",
    "# join the two \n",
    "result = result.merge(result_count, on='superkingdom')\n",
    "\n",
    "display(result)\n",
    "\n",
    "\n",
    "# now plot\n",
    "N = len(list(set(result.superkingdom)))\n",
    "insol = result.Insoluble.values\n",
    "inact = result.Inactive.values\n",
    "act = result.Active.values\n",
    "ind = np.arange(N)    # the x locations for the groups\n",
    "width = 0.5       # the width of the bars: can also be len(x) sequence\n",
    "\n",
    "p1 = plt.bar(ind, insol, width, \n",
    "            color=insoluble)\n",
    "p2 = plt.bar(ind, inact, width,\n",
    "             bottom=insol, \n",
    "            color=inactive)\n",
    "p3 = plt.bar(ind, act, width,\n",
    "             bottom=insol+inact, \n",
    "            color=active)\n",
    "\n",
    "# add labels on top of bars\n",
    "for i, v in enumerate(result['count'].values):\n",
    "    plt.text(x=i-0.1, \n",
    "             y=1.01, \n",
    "             s=str(v), \n",
    "             color='black', \n",
    "             fontweight='normal',\n",
    "             fontsize=font_size)\n",
    "\n",
    "# tweak the axis\n",
    "plt.xticks(ind, result.superkingdom.values, rotation=45)\n",
    "plt.yticks(np.arange(0, 1.3, 0.2))\n",
    "plt.legend((p1[0], p2[0], p3[0]), ('Insoluble', 'Inactive', 'Active'),\n",
    "           fontsize=font_size,\n",
    "           loc='lower left',\n",
    "           bbox_to_anchor=(0, 1.02, 1, 0.2),\n",
    "           mode = 'expand',\n",
    "           ncol=2)\n",
    "plt.xlabel('Category', fontsize=font_size)\n",
    "plt.ylabel('Fraction', fontsize=font_size)\n",
    "plt.tick_params(labelsize=font_size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# sixth plot (identity t-SNE)\n",
    "plt.subplot(2, 3, 6)\n",
    "\n",
    "sort_mask = np.argsort(prop_data.max_all_sim.values)\n",
    "\n",
    "sc = plt.scatter(my_plot[:,0][sort_mask], my_plot[:,1][sort_mask], \n",
    "                 s=small_point, \n",
    "                 c=prop_data.max_all_sim.values[sort_mask], \n",
    "                 cmap='magma_r', # low contrast: 'viridis' 'plasma' high contrast: 'inferno' 'magma'\n",
    "                 vmin=0,\n",
    "                 vmax=100)\n",
    "#plt.gca().get_xaxis().set_ticklabels([])\n",
    "#plt.gca().get_yaxis().set_ticklabels([])\n",
    "plt.xlabel('Dimension 1',fontsize=font_size)\n",
    "plt.ylabel('Dimension 2',fontsize=font_size)\n",
    "cb = fig.colorbar(sc)\n",
    "cb.ax.tick_params(labelsize=font_size) \n",
    "plt.tick_params(labelsize=font_size)\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "# plt.savefig(join(FIGURES, 'figure2.png'), dpi=300, facecolor='w', edgecolor='w',\n",
    "#         orientation='portrait', papertype=None, format=None,\n",
    "#         transparent=False, bbox_inches=None, pad_inches=0.1,\n",
    "#         frameon=None, metadata=None)\n",
    "\n",
    "\n",
    "# plt.savefig(join(FIGURES, 'figure2.pdf'), facecolor='w', edgecolor='w',\n",
    "#         orientation='portrait', papertype=None, format=None,\n",
    "#         transparent=False, bbox_inches=None, pad_inches=0.1,\n",
    "#         frameon=None, metadata=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Old Figure 3: Part showing \"phylogenetic tree\" view with the substrates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all soluble sequences\n",
    "df_subset = prop_data.loc[prop_data['total_soluble']=='Yes']\n",
    "display(df_subset.head())\n",
    "\n",
    "soluble_ids = df_subset.uid.values\n",
    "\n",
    "# filter the identity matrix to contain only these\n",
    "data_matrix = filter_matrix_for_ids(data_matrix=df_ident, id_list=soluble_ids)\n",
    "display(data_matrix.shape)\n",
    "\n",
    "\n",
    "# make dendrogram\n",
    "den = den_from_id_matrix(data_matrix, linkage_type='ward')\n",
    "\n",
    "# get info from the dendrogam\n",
    "coordinate_data, label_data = extract_plotting_coordinates(den)\n",
    "\n",
    "# load up the data from both batches\n",
    "data1 = pd.read_csv(join(FINAL, 'experiments', '1.1.3.15_detailed_batch1.csv'), sep=';', index_col=0)\n",
    "data2 = pd.read_csv(join(FINAL, 'experiments', '1.1.3.15_detailed_batch2.csv'), sep=';', index_col=0)\n",
    "substrate_data = data1.append(data2)\n",
    "\n",
    "# keep only soluble ones\n",
    "substrate_data = substrate_data.loc[soluble_ids]\n",
    "\n",
    "# convert to a dictionary\n",
    "substrate_data_dict = substrate_data.to_dict('index')\n",
    "\n",
    "# # look at one entry\n",
    "# substrate_data[list(data_dict.keys())[0]]\n",
    "\n",
    "# get a dictionary with properties that I want to color\n",
    "property_frame = df_subset[['uid', 'superkingdom', 'cluster', 'total_active']].set_index('uid')\n",
    "property_dict = property_frame.to_dict('index')\n",
    "\n",
    "\n",
    "\n",
    "# assign property colors\n",
    "property_colors = {'cluster':{'cluster_0':cluster0, 'cluster_1':cluster1, 'cluster_2':cluster2, \n",
    "                              'cluster_3':cluster3, 'cluster_4':cluster4, 'cluster_5':cluster5, \n",
    "                              'cluster_6':cluster6, 'cluster_7':cluster7, 'cluster_8':cluster8, \n",
    "                              'cluster_9':cluster9},\n",
    "                   'total_active':{'No':inactive, 'Yes':active},\n",
    "                   'superkingdom':{'Archaea':archaea,'Bacteria':bacteria, 'Eukaryota':eukaryota, 'Other':other}}\n",
    "\n",
    "\n",
    "# make the plot\n",
    "vislib.substrate(data=label_data, \n",
    "                 dend_data=coordinate_data, \n",
    "                 subst_data=substrate_data_dict, \n",
    "                 subst_data_replicate=substrate_data_dict, \n",
    "                 property_dict=property_dict, \n",
    "                 property_colors=property_colors, \n",
    "                 filepath=join(FIGURES, 'figure3_qualitative.svg'), \n",
    "                 main='1.1.3.15')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 2: Part showing \"phylogenetic tree\" view with the substrates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is this junk? The old way of calculating perhaps?\n",
    "\n",
    "# data = pd.read_csv(filepath, index_col = 'protein', sep='\\t')\n",
    "\n",
    "# # rename protein column\n",
    "# data.index.name = 'uid'\n",
    "\n",
    "# # subtract the blank from the other activities\n",
    "# ratio_df = data.sub(data.blank, axis=0)\n",
    "\n",
    "# #display(ratio_df.head())\n",
    "\n",
    "\n",
    "# # average the three measurements\n",
    "# by_protein = ratio_df.groupby(by = 'uid')\n",
    "# meandf = by_protein.mean()\n",
    "# stdevdf = by_protein.std()\n",
    "\n",
    "# # take mean of BSA control and add two standard deviations\n",
    "# meandf.loc['BSA_stdev'] = stdevdf.loc['BSA_control']\n",
    "# meandf.loc['BSA_mean'] =  meandf.loc['BSA_control']\n",
    "\n",
    "# # subtract the LOD and only keep what's larger\n",
    "# hit_df = meandf - meandf.loc['BSA_mean']\n",
    "# hit_df = hit_df[hit_df > 3*meandf.loc['BSA_stdev']]\n",
    "\n",
    "# # drop unneeded columns\n",
    "# hit_df = hit_df.drop(['BSA_control', 'no_protein', 'BSA_stdev', 'BSA_mean'], axis=0)\n",
    "# hit_df = hit_df.drop(['blank'], axis = 1)\n",
    "\n",
    "# # drop lines with only nan and replace nan with 0\n",
    "# hit_df.dropna(how='all', axis=0, inplace=True)\n",
    "# hit_df = hit_df.replace(np.nan, 0, regex=True)\n",
    "\n",
    "# #display(hit_df)\n",
    "\n",
    "# # normalize to the highest value\n",
    "# hit_df_norm = hit_df.div(hit_df.max(axis=1), axis=0)\n",
    "\n",
    "# # add in an identifier column\n",
    "# #hit_df_norm['uid'] = hit_df_norm.index\n",
    "\n",
    "# #display(hit_df_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9, 6))\n",
    "\n",
    "\n",
    "# first plot the sequences that were active with the different substrates\n",
    "plt.subplot(2, 3, 1)\n",
    "\n",
    "background = count_result['Yes'] == 0\n",
    "plt.scatter(my_plot[:,0][background], my_plot[:,1][background], s=small_point, color=other)\n",
    "\n",
    "colors = [cluster3, cluster1, cluster2, cluster0, cluster4]\n",
    "\n",
    "for i, subst in enumerate(substrates):\n",
    "\n",
    "    if subst == 'promiscuous':\n",
    "        act_w_subst = count_result['Yes'] >= 3 \n",
    "\n",
    "    elif subst == 'glycolate':\n",
    "        act_w_subst = (props_and_experiments['glycolate'] == 'Yes') & (count_result['Yes'] == 1)\n",
    "\n",
    "    elif subst == 'lactate':\n",
    "        act_w_subst = (props_and_experiments['lactate'] == 'Yes') & (count_result['Yes'] == 1)\n",
    "\n",
    "    elif subst == 'mandelate':  \n",
    "        act_w_subst = (props_and_experiments['mandelate'] == 'Yes') & (count_result['Yes'] == 1)\n",
    "\n",
    "    elif subst == '2-hydroxyglutarate':  \n",
    "        act_w_subst = (props_and_experiments['2-hydroxyglutarate'] == 'Yes') & (count_result['Yes'] == 1)\n",
    "\n",
    "    # plot the sequences active with that substrate\n",
    "    plt.scatter(my_plot[:,0][act_w_subst], my_plot[:,1][act_w_subst], \n",
    "                s=large_point, \n",
    "                color=colors[i])\n",
    "\n",
    "# add legend to plot        \n",
    "plt.legend(['Other'] + substrates, \n",
    "           fontsize=font_size,\n",
    "           loc='lower left',\n",
    "           bbox_to_anchor=(0, 1.02, 1, 0.2),\n",
    "           mode = 'expand',\n",
    "           ncol=2)\n",
    "\n",
    "plt.xlabel('Dimension 1', fontsize=font_size)\n",
    "plt.ylabel('Dimension 2', fontsize=font_size)\n",
    "plt.tick_params(labelsize=font_size)\n",
    "        \n",
    "# now make a plot each with the identity of all sequences compared to this\n",
    "for i, subst in enumerate(substrates):\n",
    "    \n",
    "    ident_key = '%s_sim' % subst\n",
    "    \n",
    "    \n",
    "    # make a plot\n",
    "    font_size = 7\n",
    "    plt.subplot(2, 3, i+2)\n",
    "\n",
    "    sc = plt.scatter(my_plot[:,0], my_plot[:,1],\n",
    "            s=5,\n",
    "            c=props_and_experiments[ident_key].values,\n",
    "            cmap='magma_r', # low contrast: 'viridis' 'plasma' high contrast: 'inferno' 'magma'\n",
    "            vmin=0,\n",
    "            vmax=100)\n",
    "\n",
    "    plt.title(subst, fontsize=font_size+2)\n",
    "    plt.xlabel('Dimension 1', fontsize=font_size)\n",
    "    plt.ylabel('Dimension 2', fontsize=font_size)\n",
    "\n",
    "    cb = fig.colorbar(sc)\n",
    "    cb.ax.tick_params(labelsize=font_size) \n",
    "    plt.tick_params(labelsize=font_size)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.savefig(join(FIGURES, 'figure4.png'), dpi=300, facecolor='w', edgecolor='w',\n",
    "        orientation='portrait', papertype=None, format=None,\n",
    "        transparent=False, bbox_inches=None, pad_inches=0.1,\n",
    "        frameon=None, metadata=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = prop_data[(prop_data.total_soluble == 'Yes') & (prop_data.total_active == 'Yes')]\n",
    "temp_df[['uid', 'superkingdom', 'pfam', 'cluster']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look across the sequences to see how the MI algorithm sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqsample import distance\n",
    "from Bio import SeqIO\n",
    "\n",
    "# load up the alignments and collect all the sequences\n",
    "alignment_path = join(FINAL, 'BRENDA', 'cluster_0_alignment.fasta')\n",
    "headers = []\n",
    "all_seq = []\n",
    "active_seq = []\n",
    "\n",
    "for record in SeqIO.parse(alignment_path, \"fasta\"):\n",
    "    header = record.id.split(';')[0]\n",
    "    seq = record.seq\n",
    "    \n",
    "    headers.append(header)\n",
    "    all_seq.append(seq)\n",
    "    \n",
    "    if header in prop_data[prop_data.total_active=='Yes'].uid.values:\n",
    "        active_seq.append(seq)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "def count_symbols_per_pos(seq_list, selected_seq_list, gap_cutoff=0.75):\n",
    "    '''\n",
    "    Count how many symbols occur at each position in an alignment.\n",
    "    Exclude positions where the number of gaps are above specified cutoff.\n",
    "    '''\n",
    "    counts = [[] for s in range(len(seq_list[0]))]\n",
    "    for line in seq_list:\n",
    "        for i, symbol in enumerate(line):\n",
    "            #if symbol == '-':\n",
    "            #    continue\n",
    "            counts[i].append(symbol.lower())\n",
    "\n",
    "    selected_counts = [[] for s in range(len(seq_list[0]))]\n",
    "    for line in selected_seq_list:\n",
    "        for i, symbol in enumerate(line):\n",
    "            #if symbol == '-':\n",
    "            #    continue\n",
    "            selected_counts[i].append(symbol.lower())\n",
    "            \n",
    "    # now remove positions with too many gaps\n",
    "    no_gap_counts = []\n",
    "    no_gap_selected_counts = []\n",
    "    for i, c in enumerate(counts):\n",
    "        if c.count('-')/len(c) < gap_cutoff:\n",
    "            no_gap_counts.append(c)\n",
    "            no_gap_selected_counts.append(selected_counts[i])\n",
    "            \n",
    "            \n",
    "    return [len(set(s)) if '-' not in s else len(set(s))-1 for s in no_gap_counts], [len(set(s)) if '-' not in s else len(set(s))-1 for s in no_gap_selected_counts], \n",
    "    \n",
    "    \n",
    "all_counts, selected_counts = count_symbols_per_pos(all_seq, active_seq)\n",
    "\n",
    "\n",
    "\n",
    "# plot histograms of how many amino acids are present at different positions\n",
    "plt.figure()\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.hist(all_counts, bins=range(0,20))\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.hist(selected_counts, bins=range(0,20))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# make a data frame\n",
    "x = pd.DataFrame({'total':all_counts, 'sampled':selected_counts})\n",
    "\n",
    "x['sampled_percent'] = 100*x.sampled/x.total\n",
    "\n",
    "# count the frequencies\n",
    "result = x.groupby('total')['sampled_percent'].mean()\n",
    "display(result)\n",
    "\n",
    "# count the frequencies\n",
    "result = x.groupby('total')['sampled'].value_counts()\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would seem that the sampling occured heavily at variable positions and not so much at semi-conserved positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 5: divide results based on promiscuous and specific and show similarity to these on scatterplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each sequence I need to get the max identity to the categories of substrate speceficity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine uid property data with ec information\n",
    "uid_data = uid_property.merge(uid_ec, on='uid')\n",
    "\n",
    "# subset to keep only 1.1.3.15\n",
    "uid_data_subset = uid_data[uid_data['ec']=='1.1.3.15']\n",
    "\n",
    "# move index column of the substrate data to a new uid column\n",
    "substrate_data['uid'] = substrate_data.index\n",
    "\n",
    "# combine with the substrate-specific data\n",
    "props_and_experiments = uid_data_subset.merge(substrate_data, \n",
    "                     on='uid', \n",
    "                     how='left')\n",
    "\n",
    "# change True to Yes and False to No\n",
    "props_and_experiments.replace(True, 'Yes', regex=False, inplace=True)\n",
    "props_and_experiments.replace(False, 'No', regex=False, inplace=True)\n",
    "\n",
    "# sort property data to be in the same order as the other data\n",
    "props_and_experiments['sort_cat'] = pd.Categorical(props_and_experiments['uid'], \n",
    "                                          categories=prop_data.uid, \n",
    "                                          ordered=True)\n",
    "props_and_experiments.sort_values('sort_cat', inplace=True)\n",
    "props_and_experiments.reset_index(inplace=True)\n",
    "props_and_experiments = props_and_experiments.drop(['sort_cat', 'index'], axis=1)\n",
    "\n",
    "\n",
    "# filter the identity matrix to contain only the identifiers that I'm using\n",
    "identity_data = filter_matrix_for_ids(data_matrix=df_ident, id_list=props_and_experiments.uid.values)\n",
    "display(identity_data.shape)\n",
    "\n",
    "# sort identity data to be in the same order as the other\n",
    "identity_data['uid'] = identity_data.index\n",
    "identity_data['sort_cat'] = pd.Categorical(identity_data['uid'], \n",
    "                                          categories=prop_data.uid, \n",
    "                                          ordered=True)\n",
    "identity_data.sort_values('sort_cat', inplace=True)\n",
    "identity_data.reset_index(inplace=True)\n",
    "\n",
    "# put back the index and drop unneeded columns\n",
    "identity_data.index = identity_data.uid\n",
    "identity_data = identity_data.drop(['sort_cat', 'index', 'uid'], axis=1)\n",
    "\n",
    "\n",
    "# get only the substrate columns\n",
    "data_substrates = props_and_experiments[['glycolate', 'lactate', 'mandelate', '2-hydroxyglutarate', '2-hydroxyoctanoate', '2-hydroxystearate']]\n",
    "count_result = data_substrates.apply(pd.Series.value_counts, axis=1)[['Yes']].fillna(0)\n",
    "\n",
    "substrates = ['promiscuous', 'glycolate', \n",
    "              'lactate', 'mandelate',\n",
    "            '2-hydroxyglutarate']\n",
    "for i, subst in enumerate(substrates):\n",
    "\n",
    "    if subst == 'promiscuous':\n",
    "        selected = props_and_experiments[count_result['Yes'] >= 3]\n",
    "\n",
    "    elif subst == 'glycolate':\n",
    "        selected = props_and_experiments[(props_and_experiments['glycolate'] == 'Yes') & (count_result['Yes'] == 1)]\n",
    "\n",
    "    elif subst == 'lactate':\n",
    "        selected = props_and_experiments[(props_and_experiments['lactate'] == 'Yes') & (count_result['Yes'] == 1)]\n",
    "\n",
    "    elif subst == 'mandelate':  \n",
    "        selected = props_and_experiments[(props_and_experiments['mandelate'] == 'Yes') & (count_result['Yes'] == 1)]\n",
    "\n",
    "    elif subst == '2-hydroxyglutarate':  \n",
    "        selected = props_and_experiments[(props_and_experiments['2-hydroxyglutarate'] == 'Yes') & (count_result['Yes'] == 1)]\n",
    "\n",
    "\n",
    "\n",
    "    # # get a list with all the identifiers not selected\n",
    "    # not_selected = moran_subset[moran_subset.in_brenda == 'No']\n",
    "\n",
    "    # # make sure all the identifiers are present in the identity matrix\n",
    "    # for uid in selected.uid.values:\n",
    "    #     assert uid in df_ident.index, 'Error, %s not present in identity matrix' % uid\n",
    "\n",
    "    # for uid in not_selected.uid.values:\n",
    "    #     assert uid in df_ident.index, 'Error, %s not present in identity matrix' % uid\n",
    "\n",
    "\n",
    "    # make a subset of the identity matrix\n",
    "    df_ident_selected = identity_data.loc[selected.uid.values]\n",
    "\n",
    "    ident_key = '%s_sim' % subst\n",
    "    sim_data = {'uid':[], ident_key:[]}\n",
    "    for uid in props_and_experiments.uid.values:\n",
    "        sim_data['uid'].append(uid)\n",
    "        sim_data[ident_key].append(max(df_ident_selected[uid].values))\n",
    "\n",
    "        \n",
    "    # merge with the other data\n",
    "    sim_data_df = pd.DataFrame(sim_data)\n",
    "    props_and_experiments = props_and_experiments.merge(sim_data_df, on=['uid'])\n",
    "    \n",
    "display(props_and_experiments.head())\n",
    "display(props_and_experiments.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(vislib)\n",
    "\n",
    "# select all soluble sequences with the FMN dh domain \n",
    "df_subset = prop_data.loc[prop_data['total_soluble']=='Yes']\n",
    "display(df_subset.head())\n",
    "\n",
    "soluble_ids = df_subset.uid.values\n",
    "\n",
    "# filter the identity matrix to contain only these\n",
    "data_matrix = filter_matrix_for_ids(data_matrix=df_ident, id_list=soluble_ids)\n",
    "display(data_matrix.shape)\n",
    "\n",
    "\n",
    "# make dendrogram\n",
    "den = den_from_id_matrix(data_matrix, linkage_type='ward')\n",
    "\n",
    "# get info from the dendrogam\n",
    "coordinate_data, label_data = extract_plotting_coordinates(den)\n",
    "\n",
    "# load up the data from both batches\n",
    "data1 = pd.read_csv(join(FINAL, 'experiments', '1.1.3.15_detailed_batch1.csv'), sep=';', index_col=0)\n",
    "data2 = pd.read_csv(join(FINAL, 'experiments', '1.1.3.15_detailed_batch2.csv'), sep=';', index_col=0)\n",
    "substrate_data = data1.append(data2)\n",
    "\n",
    "# keep only soluble ones\n",
    "substrate_data = substrate_data.loc[soluble_ids]\n",
    "\n",
    "# set all values to zero\n",
    "substrate_data = substrate_data.replace(True, 0)\n",
    "\n",
    "\n",
    "# convert to a dictionary\n",
    "substrate_data_dict = substrate_data.to_dict('index')\n",
    "\n",
    "# now combined with the quantitative data loaded before\n",
    "both_batches_dict = both_batches.set_index('uid').to_dict('index')\n",
    "\n",
    "# both_batches only have data for some of the sequences, need to add zeros for soluble but non-active ones\n",
    "for uid in sorted(substrate_data_dict.keys()):\n",
    "    if both_batches_dict.get(uid) is None:\n",
    "        both_batches_dict[uid] = substrate_data_dict[uid]\n",
    "\n",
    "# assign substrate colors\n",
    "cmap = matplotlib.cm.get_cmap('Purples')\n",
    "\n",
    "for uid in sorted(both_batches_dict.keys()):\n",
    "    for substrate in both_batches_dict[uid].keys():\n",
    "        \n",
    "        rgba = cmap(both_batches_dict[uid][substrate])\n",
    "        color = matplotlib.colors.to_hex(rgba, keep_alpha=False)\n",
    "        both_batches_dict[uid][substrate] = color\n",
    "        \n",
    "\n",
    "# get a dictionary with properties that I want to color\n",
    "property_frame = df_subset[['uid', 'superkingdom', 'cluster']].set_index('uid')\n",
    "property_dict = property_frame.to_dict('index')\n",
    "\n",
    "\n",
    "\n",
    "# assign property colors\n",
    "property_colors = {'cluster':{'cluster_0':cluster0, 'cluster_1':cluster1, 'cluster_2':cluster2, \n",
    "                              'cluster_3':cluster3, 'cluster_4':cluster4, 'cluster_5':cluster5, \n",
    "                              'cluster_6':cluster6, 'cluster_7':cluster7, 'cluster_8':cluster8, \n",
    "                              'cluster_9':cluster9},\n",
    "                   'superkingdom':{'Archaea':archaea,'Bacteria':bacteria, 'Eukaryota':eukaryota, 'Other':other}}\n",
    "\n",
    "\n",
    "# make the plot\n",
    "vislib.substrate(data=label_data, \n",
    "                 dend_data=coordinate_data, \n",
    "                 subst_data=both_batches_dict, \n",
    "                 subst_data_replicate=both_batches_dict, \n",
    "                 property_dict=property_dict, \n",
    "                 property_colors=property_colors, \n",
    "                 filepath=join(FIGURES, 'old_figure2_5x.svg'), \n",
    "                 main='1.1.3.15',\n",
    "                 substrate_order=['glycolate', 'lactate', '2-hydroxyoctanoate', \n",
    "                                  'mandelate', '2-hydroxystearate', '2-hydroxyglutarate'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
